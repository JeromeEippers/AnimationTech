{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88848698-aec5-416c-ab9d-df83bbae2bf6",
   "metadata": {},
   "source": [
    "# Motion Fields for Interactive Character Animation\n",
    "\n",
    "by Yongjoon Lee, Kevin Wampler, Gilbert Bernstein, Jovan Popovic, Zoran Popovic  \n",
    "2010\n",
    "\n",
    "Notebook by Jerome Eippers, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29060b4-15df-4ab3-a04d-2db952f34452",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pickle\n",
    "from dataclasses import dataclass, field\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "from ipywidgets import widgets, interact\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import ipyanimlab as lab\n",
    "\n",
    "viewer = lab.Viewer(move_speed=5, width=1280, height=720)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a87091-9a8c-4170-bdea-51367763963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the character\n",
    "character = viewer.import_usd_asset('AnimLabSimpleMale.usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742c24d-a7ba-4e37-8de0-4044474d1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_asset = viewer.import_usd_asset('../../meshes/displacement.usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad580b-b79d-4c36-af1a-59acf100abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "animmap = lab.AnimMapper(character, keep_translation=False, root_motion=True, match_effectors=True, local_offsets={'Hips':[0, 2, 0]})\n",
    "animations = []\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk1_subject1.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk1_subject2.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk1_subject5.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk2_subject1.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk2_subject3.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk2_subject4.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk3_subject1.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk3_subject2.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk3_subject3.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk3_subject4.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk3_subject5.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/walk4_subject1.bvh', anim_mapper=animmap))\n",
    "\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/run1_subject2.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/run1_subject5.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/run2_subject1.bvh', anim_mapper=animmap))\n",
    "animations.append(lab.import_bvh(f'../../resources/lafan1/bvh/run2_subject4.bvh', anim_mapper=animmap))\n",
    "\n",
    "bone_count = character.bone_count()\n",
    "bones = animations[0].bones\n",
    "parents = animations[0].parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed84b32-3cc3-4859-87f6-edc1e553dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = []\n",
    "for anim in animations:\n",
    "    _, p = lab.utils.quat_fk(anim.quats, anim.pos, parents)\n",
    "    contacts.append(lab.utils.extract_feet_contacts(p, bones.index('LeftToe'), bones.index('RightToe'), 0.1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba79263-eddd-46e4-a0fe-82f7b2d67292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, index=0):\n",
    "\n",
    "    frame = min(frame, animations[index].quats.shape[0] -1)\n",
    "    q = (animations[index].quats[frame,...])\n",
    "    p = (animations[index].pos[frame,...])\n",
    "        \n",
    "    a =  lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "   \n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=5000),\n",
    "    index=widgets.IntSlider(max=len(animations)-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338fac1-4fa8-4a4c-b5a1-20787d257ac3",
   "metadata": {},
   "source": [
    "## Motion states and notation\n",
    "\n",
    "A **pose** is written as\n",
    "$$\n",
    "x = (x_{\\text{root}}, x_{\\text{hips}}, p_0, p_1, \\dots, p_n),\n",
    "$$\n",
    "where $x_{\\text{root}}, x_{\\text{hips}}\\in\\mathbb{R}^3$ is the root position and hips positions and $p_i$ are unit quaternions for joint orientations.\n",
    "\n",
    "Given two successive poses $x$ and $x'$ we define a finite-difference **velocity**\n",
    "$$\n",
    "v = x' \\ominus x\n",
    "= \\big( x'_{\\text{root}} - x_{\\text{root}},\\; x'_{\\text{hips}} - x_{\\text{hips}},\\;p'_0 p_0^{-1},\\; p'_1 p_1^{-1},\\; \\dots,\\; p'_n p_n^{-1} \\big).\n",
    "$$\n",
    "\n",
    "We add a velocity to a pose with the operator \n",
    "$$\n",
    "    x' = x \\oplus v.\n",
    "$$\n",
    "\n",
    "---\n",
    "A **motion state** is\n",
    "$$\n",
    "m = (x, v).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2bd4e-59bf-426a-aab3-b4f6327cc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_skeleton_p = (animations[0].pos[0,...]).copy()\n",
    "default_skeleton_p[0] = 0\n",
    "\n",
    "POSESHAPE = (bone_count + 2, 4)\n",
    "\n",
    "class PoseData:\n",
    "    def __init__(self, root, hips, quats):\n",
    "        self.root = root\n",
    "        self.hips = hips\n",
    "        self.quats = quats\n",
    "\n",
    "def pose_pack(root, hips, quats):\n",
    "    result = np.zeros(POSESHAPE, dtype=np.float32)\n",
    "    result[0, :3] = root\n",
    "    result[1, :3] = hips\n",
    "    result[2:, :] = quats\n",
    "    return result\n",
    "\n",
    "def pose_unpack(pose):\n",
    "    root = pose[..., 0, :3]\n",
    "    hips = pose[..., 1, :3]\n",
    "    quats = pose[..., 2:, :]\n",
    "    return PoseData( root, hips, quats )\n",
    "\n",
    "def pose_add(x, v):\n",
    "    x = pose_unpack(x)\n",
    "    v = pose_unpack(v)\n",
    "\n",
    "    _, root = lab.utils.qp_mul((x.quats[0], x.root), (v.quats[0], v.root))\n",
    "    hips = x.hips + v.hips\n",
    "    quats = lab.utils.normalize(lab.utils.quat_mul(x.quats, v.quats))\n",
    "\n",
    "    return pose_pack(root, hips, quats)\n",
    "\n",
    "def pose_subtract(a, b):\n",
    "    a = pose_unpack(a)\n",
    "    b = pose_unpack(b)\n",
    "\n",
    "    _, root = lab.utils.qp_mul(lab.utils.qp_inv((b.quats[0], b.root)), (a.quats[0], a.root))\n",
    "    hips = a.hips - b.hips\n",
    "    quats = lab.utils.normalize(lab.utils.quat_mul(lab.utils.quat_inv(b.quats), a.quats))\n",
    "    flip = quats[:, 0] < 0\n",
    "    quats[flip, :] = -quats[flip, :]\n",
    "\n",
    "    return pose_pack(root, hips, quats)\n",
    "\n",
    "def pose_lerp(a, b, t):\n",
    "    a = pose_unpack(a)\n",
    "    b = pose_unpack(b)\n",
    "\n",
    "    root = (1.0-t) * a.root + (t) * b.root\n",
    "    hips = (1.0-t) * a.hips + (t) * b.hips\n",
    "    quats = lab.utils.normalize(lab.utils.quat_slerp(a.quats, b.quats, t))\n",
    "    \n",
    "    return pose_pack(root, hips, quats)\n",
    "\n",
    "def pose_blend(states, weights):\n",
    "    states = pose_unpack(states)\n",
    "\n",
    "    root = np.sum(states.root * weights[:, np.newaxis], axis=0)\n",
    "    hips = np.sum(states.hips * weights[:, np.newaxis], axis=0)\n",
    "    quats = lab.utils.normalize(np.sum(states.quats* weights[:, np.newaxis, np.newaxis], axis=0))\n",
    "    \n",
    "    return pose_pack(root, hips, quats)\n",
    "\n",
    "def pose_to_qp(a):\n",
    "    a = pose_unpack(a)\n",
    "    p = default_skeleton_p.copy()\n",
    "    p[0, :] = a.root\n",
    "    p[1, :] = a.hips\n",
    "    return a.quats.copy(), p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b0c18-60a5-48b8-9aa4-a281c9b4dd82",
   "metadata": {},
   "source": [
    "## Build the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2792a-1d8e-4a09-9a9a-b316be2f16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_x = np.zeros([50000, bone_count+2, 4], dtype=np.float32)\n",
    "states_v = np.zeros([50000, bone_count+2, 4], dtype=np.float32)\n",
    "states_y = np.zeros([50000, bone_count+2, 4], dtype=np.float32)\n",
    "states_c = np.zeros([50000, 2], dtype=np.bool)\n",
    "states_count = 0\n",
    "\n",
    "def add_states_ex(quats, pos, lcontact, rcontact):\n",
    "    global states_count\n",
    "  \n",
    "    for i in range(quats.shape[0] - 2):\n",
    "        a = pose_pack(pos[i, 0, :].copy(), pos[i, 1, :].copy(), quats[i,...].copy() )\n",
    "        b = pose_pack(pos[i+1, 0, :].copy(), pos[i+1, 1, :].copy(), quats[i+1,...].copy() )\n",
    "        c = pose_pack(pos[i+2, 0, :].copy(), pos[i+2, 1, :].copy(), quats[i+2,...].copy() )\n",
    "\n",
    "        y = pose_subtract(c, b)\n",
    "        v = pose_subtract(b, a)\n",
    "        a = pose_unpack(a)\n",
    "        a.root[:] = 0\n",
    "        a.quats[0, :] = [1,0,0,0]\n",
    "        a = pose_pack(a.root, a.hips, a.quats)\n",
    "\n",
    "        states_x[states_count, :, :] = a\n",
    "        states_v[states_count, :, :] = v\n",
    "        states_y[states_count, :, :] = y\n",
    "\n",
    "        states_c[states_count, 0] = lcontact[i]\n",
    "        states_c[states_count, 1] = rcontact[i]\n",
    "        \n",
    "        states_count += 1\n",
    "\n",
    "def add_states(anim_id, timings):\n",
    "    add_states_ex(animations[anim_id].quats[timings], animations[anim_id].pos[timings], contacts[anim_id][0][timings], contacts[anim_id][1][timings])\n",
    "\n",
    "\n",
    "# Walk :\n",
    "add_states(2, slice(100,2800))\n",
    "end_of_walk_ids = states_count\n",
    "\n",
    "# Jog :\n",
    "add_states(15, slice(1200,1800))\n",
    "add_states(15, slice(3450,3860))\n",
    "add_states(14, slice(180,800))\n",
    "add_states(13, slice(200,2300))\n",
    "    \n",
    "states_x = states_x[:states_count, ...]\n",
    "states_v = states_v[:states_count, ...]\n",
    "states_y = states_y[:states_count, ...]\n",
    "states_c = states_c[:states_count, ...]\n",
    "states_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431b1da-7497-45b0-9d2d-8757e8942f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, next_state=False):\n",
    "\n",
    "    controller_orient = np.array([1,0,0,0], dtype=np.float32)       \n",
    "    display(states_c[frame])\n",
    "\n",
    "    state = states_x[frame].copy()\n",
    "    if next_state:\n",
    "        state = pose_add(state, states_v[frame])\n",
    "    q, p = pose_to_qp(state)\n",
    "\n",
    "    angle = np.atan2(p[0, 0], p[0, 2])\n",
    "    controller_orient[0] = np.cos(angle/2)\n",
    "    controller_orient[2] = np.sin(angle/2)\n",
    "        \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    d = lab.utils.quat_to_mat(q[0], p[0])\n",
    "    viewer.draw(displacement_asset, d)\n",
    "\n",
    "    d = lab.utils.quat_to_mat(controller_orient, p[0])\n",
    "    viewer.draw(displacement_asset, d)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "   \n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=states_count-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337808c-7914-48b4-a12c-a2663544283f",
   "metadata": {},
   "source": [
    "## Similarity metric and similarity weights\n",
    "\n",
    "Similarity between motion states is computed in this case computed using the positions of each bone and their velocities (unlike the paper that uses rotation info)\n",
    "\n",
    "Given the $k$ nearest neighbours $\\{m_i\\}$ of $m$, we use inverse-distance weights (normalized) for interpolation:\n",
    "$$\n",
    "w_i \\;=\\; \\frac{\\dfrac{1}{d(m,m_i)^2}}{\\sum_j \\dfrac{1}{d(m,m_j)^2}}.\n",
    "$$\n",
    "These $w_i$ are called *similarity weights* and are used both for interpolation and as the passive action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93832171-034c-46cb-b9c6-5f42873f6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SHAPE = (bone_count*2, 3)\n",
    "# metric_weights = np.array([0, .3, .1, .1, .01, .01, .01,  .01, .01, .01, .01,  .01, .01, .01, .01,  .2, .5, 1, 1,  .2, .5, 1, 1 ], dtype=np.float32)\n",
    "# metric_velocity_weights = np.array([1, .8, .5, .5, .5, .01, .01,  .01, .01, .01, .9,  .01, .01, .01, .9,  1.2, 1.5, 2, 0,  1.2, 1.5, 2, 0 ], dtype=np.float32)\n",
    "# metric_weights = np.ones([bone_count], dtype=np.float32)\n",
    "# metric_velocity_weights = np.ones([bone_count], dtype=np.float32)\n",
    "metric_weights = np.array([0, .3, .1, .1, .5, .01, .01,  .01, .01, .01, .01,  .01, .01, .01, .01,  .2, .5, 1, 1,  .2, .5, 1, 1 ], dtype=np.float32)\n",
    "metric_velocity_weights = np.array([1, .8, .5, .1, .1, .5, .1,  0,0,0,0, 0,0,0,0,  1.2, 1.5, 2, 0,  1.2, 1.5, 2, 0 ], dtype=np.float32)\n",
    "\n",
    "def build_distance_metric(x, v):\n",
    "\n",
    "    next_pose = pose_unpack(x.copy()) #pose_unpack(pose_add(x, v))\n",
    "    next_pose.quats[0] = [1,0,0,0]\n",
    "    _, p_a = lab.utils.quat_fk(next_pose.quats, default_skeleton_p, parents)\n",
    "\n",
    "    next_pose = pose_unpack(pose_add(pose_pack(next_pose.root, next_pose.hips, next_pose.quats), v))\n",
    "    \n",
    "    #next_pose.quats[0] = [1,0,0,0]\n",
    "    _, p_b = lab.utils.quat_fk(next_pose.quats, default_skeleton_p, parents)\n",
    "\n",
    "    return np.concatenate([p_a * metric_weights[:, np.newaxis] * .8, p_b - p_a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98466d49-9118-4abe-8cf1-a722824d235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_matrix = np.zeros([states_count, FEATURE_SHAPE[0], 3], dtype=np.float32)\n",
    "for i in range(states_count):\n",
    "    metric_matrix[i, ...] = build_distance_metric(states_x[i], states_v[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4132c-47bf-41ae-aa2d-1ae64a635be2",
   "metadata": {},
   "source": [
    "### Simple representation of the motion field\n",
    "\n",
    "This is purely for visually explaining the concept. It does not really represent anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84876af-35b0-47e0-ac75-270b9b47db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "# metric_matrix: [N_samples x N_features] matrix\n",
    "reducer = UMAP(n_components=3, metric='euclidean', n_neighbors = 80)\n",
    "embedding = reducer.fit_transform(metric_matrix.reshape(-1, FEATURE_SHAPE[0]*3))\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.cla()\n",
    "ax.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2], s=5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff8a1c-6986-42f4-ba11-62ceec5055f2",
   "metadata": {},
   "source": [
    "### Use Pytorch for knn\n",
    "\n",
    "Running in parallele on the gpu we can just do a brut force search through all the poses to find the k nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bfa01-7864-4596-9963-9f601b58376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toch_knn_features = torch.from_numpy(metric_matrix).to('cuda').unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c33a38-eaca-4cb9-b628-e88b4aa91b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nns_by_vector(vector, k):\n",
    "    query = torch.from_numpy(vector).to('cuda')\n",
    "    \n",
    "    # Expand p and q to broadcast\n",
    "    p_exp = toch_knn_features         # shape: (1, state_count, feature_count, 3)\n",
    "    q_exp = query.unsqueeze(1)                      # shape: (query_count, 1, feature_count, 3)\n",
    "    \n",
    "    diff = p_exp - q_exp            # shape: (query_count, state_count, feature_count, 3), broadcasting\n",
    "    point_distances = torch.norm(diff, dim=3)  # shape: (query_count, state_count, feature_count)\n",
    "    \n",
    "    # Step 2: sum distances per set\n",
    "    sum_distances = torch.sum(point_distances, dim=2)  # shape: (query_count, state_count)\n",
    "    \n",
    "    # Step 3: get k nearest sets for each query\n",
    "    topk = torch.topk(sum_distances, k=k, largest=False)\n",
    "    knn_indices = topk.indices.cpu().numpy()      # shape: (query_count, k)\n",
    "    knn_distances = topk.values.cpu().numpy()    # shape: (query_count, k)\n",
    "\n",
    "    return knn_indices, knn_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673af372-de30-4c82-bec7-598762293527",
   "metadata": {},
   "source": [
    "## Integration function and drift correction\n",
    "\n",
    "An action $a=[a_1,\\dots,a_k]$ is a convex combination over the neighborhood. The basic integration computes the next pose/velocity by blending the neighbour velocities and next-frame velocities:\n",
    "$$\n",
    "I(m,a) \\;=\\; \\Big(x \\oplus \\sum_{i=1}^k a_i v_i,\\; \\sum_{i=1}^k a_i y_i\\Big),\n",
    "$$\n",
    "where $y_i$ denotes the \"next\" velocity stored at neighbour $m_i$.\n",
    "\n",
    "To prevent drift into regions with little data, a small drift-correction toward the nearest database state $\\bar m=(\\bar x,\\bar v)$ is blended in with strength $\\delta$ (typical $\\delta\\!=\\!0.1$):\n",
    "$$\n",
    "v' = (1-\\delta)\\Big(x \\oplus \\sum_{i=1}^k a_i v_i\\Big) \\oplus \\delta\\big((\\bar x\\oplus\\bar v)\\ominus x\\big),\n",
    "\\qquad\n",
    "y' = (1-\\delta)\\Big(\\sum_{i=1}^k a_i y_i\\Big)\\oplus \\delta\\,\\bar y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abc3fd-d097-49ed-996b-82d02abeafe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_neighbors(current_x, current_v, k=15):\n",
    "    indices, distances = get_nns_by_vector(build_distance_metric(current_x, current_v)[np.newaxis, ...], k)\n",
    "    indices, distances = indices[0], distances[0] \n",
    "    idistances = 1.0/(distances**2 + 1e-8)\n",
    "    idistances /= np.sum(idistances)\n",
    "    return indices, idistances\n",
    "\n",
    "def get_batched_k_neighbors(metric_vector, k=15):\n",
    "    indices, distances = get_nns_by_vector(metric_vector, k)\n",
    "    idistances = 1.0/(distances**2 + 1e-8)\n",
    "    idistances /= np.sum(idistances, axis=1, keepdims=True)\n",
    "    return indices, idistances\n",
    "\n",
    "def compute_v_to_reach_state(current_x, state_id):\n",
    "    next_x = pose_add(states_x[state_id], states_v[state_id])\n",
    "    next_x = pose_unpack(next_x)\n",
    "    x = pose_unpack(current_x)\n",
    "    next_x.root += x.root\n",
    "    next_x.quats[0] = lab.utils.quat_mul(x.quats[0], next_x.quats[0])\n",
    "    next_x = pose_pack(next_x.root, next_x.hips, next_x.quats)\n",
    "    return pose_subtract(next_x, current_x)\n",
    "\n",
    "def compute_new_state(current_x, indices, weights, tug_ratio=.1):\n",
    "    tug_indice = np.argmax(weights)\n",
    "    next_v = compute_v_to_reach_state(current_x, indices[tug_indice])\n",
    "\n",
    "    blended_v = pose_blend(states_v[indices, ...], weights)\n",
    "    final_v = pose_lerp(blended_v, next_v, tug_ratio)\n",
    "\n",
    "    blended_y = pose_blend(states_y[indices, ...], weights)\n",
    "    final_y = pose_lerp(blended_y, states_y[indices[tug_indice]], tug_ratio)\n",
    "\n",
    "    return (\n",
    "        pose_add(current_x, final_v),\n",
    "        final_y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed12cbc-56bf-4dea-9861-aadad556e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indice = 0\n",
    "\n",
    "current_x = states_x[last_indice, ...].copy()\n",
    "current_v = states_v[100, ...].copy()\n",
    "\n",
    "umap_fig = plt.figure(figsize=(5, 5))\n",
    "umap_ax = umap_fig.add_subplot(111, projection='3d', computed_zorder=False)\n",
    "\n",
    "def render(frame, ratio=.1, select=0, on_spot=False, plot_map=False):\n",
    "    global last_indice\n",
    "    \n",
    "    # compute the n closest\n",
    "    indices, weights = get_k_neighbors(current_x, current_v, 15)\n",
    "\n",
    "    # display helper\n",
    "    current_pose_umap= None\n",
    "    if plot_map:\n",
    "        current_pose_umap = reducer.transform(build_distance_metric(current_x, current_v).flatten().reshape(1, -1))[0]\n",
    "\n",
    "    if select > -1:\n",
    "        weights[select] = 1.0\n",
    "        weights /= np.sum(weights)\n",
    "\n",
    "    last_indice = indices[0]\n",
    "    \n",
    "    current_x[...], current_v[...] = compute_new_state(current_x, indices, weights, ratio)\n",
    "\n",
    "    q, p = pose_to_qp(current_x)\n",
    "    \n",
    "    display((indices, weights))\n",
    "\n",
    "    if on_spot:\n",
    "        p[0] = [0, 0, 200]\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "\n",
    "    character.materials()[0].set_albedo(np.array([.4, .4, .8], dtype=np.float32))\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    for i in range(15):\n",
    "        q, p = pose_to_qp(states_x[indices[i]])\n",
    "        e = lab.utils.quat_to_mat(q, p)\n",
    "        character.materials()[0].set_albedo( np.ones(3, dtype=np.float32)* float(weights[i]) )\n",
    "        e[0, 0, 3] = i * 40\n",
    "        viewer.draw(character, e)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "\n",
    "    # Create matplotlib figure\n",
    "    if plot_map:\n",
    "        umap_ax.cla()\n",
    "        \n",
    "        # Plot all database points (light gray)\n",
    "        \n",
    "    \n",
    "        umap_ax.scatter(current_pose_umap[0], current_pose_umap[1], current_pose_umap[2],\n",
    "                      c='red', s=200, marker='*', edgecolors='black', \n",
    "                      linewidth=1, label='Current pose', zorder=10)\n",
    "    \n",
    "        neighbor_points = embedding[indices, :]\n",
    "        umap_ax.scatter(neighbor_points[:, 0], neighbor_points[:, 1], neighbor_points[:, 2], \n",
    "                       c=weights, cmap='viridis', s=100, \n",
    "                       edgecolors='blue', linewidth=0.5, \n",
    "                       label='Neighbors', zorder=5)\n",
    "\n",
    "        umap_ax.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2],\n",
    "                  c='lightgray', s=20, alpha=0.6, label='Database poses')\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=widgets.Play(interval=1000./30.), #lab.Timeline(max=100),\n",
    "    ratio=widgets.FloatSlider(min=0, max=1.0, value=.1),\n",
    "    select=widgets.IntSlider(min=-1, max=14, value=-1)\n",
    ")\n",
    "\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e77e5d-8a89-46df-855b-b53bd10cdd4d",
   "metadata": {},
   "source": [
    "## Greedy action selection from k-NN\n",
    "\n",
    "At each motion state $m$, we consider a set of discrete candidate actions.  \n",
    "Each action is constructed from the similarity weights of the $k$ nearest neighbors.\n",
    "\n",
    "\n",
    "\n",
    "**Step 1: Base weights**  \n",
    "From the k-NN search, compute similarity weights\n",
    "$$\n",
    "w_i = \\frac{1/d(m,m_i)^2}{\\sum_{j=1}^k 1/d(m,m_j)^2}, \\qquad i=1,\\dots,k.\n",
    "$$\n",
    "\n",
    "These form the *passive action* (a convex combination of neighbors).\n",
    "\n",
    "\n",
    "\n",
    "**Step 2: Action generation**  \n",
    "To explore different transitions, we derive one candidate action per neighbor:\n",
    "\n",
    "- For neighbor $i$, define raw weights\n",
    "  $$\n",
    "  \\tilde{a}_j =\n",
    "  \\begin{cases}\n",
    "    1, & j=i, \\\\\n",
    "    w_j, & j \\neq i.\n",
    "  \\end{cases}\n",
    "  $$\n",
    "\n",
    "- Renormalize to obtain a valid action vector\n",
    "  $$\n",
    "  a_j = \\frac{\\tilde{a}_j}{\\sum_{\\ell=1}^k \\tilde{a}_\\ell}.\n",
    "  $$\n",
    "\n",
    "Thus each candidate action $a^{(i)}$ emphasizes a single neighbor while still respecting the similarity distribution.\n",
    "\n",
    "\n",
    "\n",
    "**Step 3: Greedy selection**  \n",
    "For greedy control (without planning), we evaluate the immediate reward (or similarity) of each candidate $a^{(i)}$ and pick\n",
    "$$\n",
    "a^\\star = \\arg\\max_{i} \\; R\\big(m, a^{(i)}\\big).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10a356-52d9-4a22-84d8-1866cb7d0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamepad = widgets.Controller(index=0)\n",
    "gamepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4399f-1e87-4a07-bb55-7c74f35ed59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NEIGHBORS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc146b4-8d7c-4801-af37-d6d99bc5a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_angle(desired: np.ndarray, current: np.ndarray, up=np.array([0,1,0])):\n",
    "    # project to ground\n",
    "    d = desired.copy(); d[1] = 0; d /= np.linalg.norm(d)+1e-12\n",
    "    c = current.copy(); c[1] = 0; c /= np.linalg.norm(c)+1e-12\n",
    "    \n",
    "    dot = np.clip(np.dot(d,c), -1.0, 1.0)\n",
    "    angle = np.acos(dot)  # magnitude\n",
    "    \n",
    "    # sign from cross product\n",
    "    cross = np.cross(c,d)  # c -> d\n",
    "    sign = np.sign(np.dot(cross, up))\n",
    "    return angle * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28239ba9-d8ac-4f35-a850-aa9122a9ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_reward(desired_direction, current_x, next_x):\n",
    "    n = pose_unpack(next_x)\n",
    "    \n",
    "    orientation = lab.utils.quat_mul_vec(n.quats[0], np.array([0,0,1], dtype=np.float32))\n",
    "\n",
    "    reward = -abs(signed_angle(desired_direction, orientation))\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6470b7c3-7b2d-4022-9970-6cecb0330e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUG_RATIO = .1\n",
    "last_indice = 400\n",
    "\n",
    "current_x = states_x[last_indice, ...].copy()\n",
    "current_v = states_v[last_indice, ...].copy()\n",
    "\n",
    "def render(frame, on_spot=False):\n",
    "\n",
    "    controller_orient = np.array([1,0,0,0], dtype=np.float32)\n",
    "    posx = gamepad.axes[0].value \n",
    "    posz = -gamepad.axes[1].value \n",
    "    if np.abs(posx) > 0.001 or np.abs(posz) > 0.001:\n",
    "        angle = np.atan2(posz, posx)\n",
    "        controller_orient[0] = np.cos(angle/2)\n",
    "        controller_orient[2] = np.sin(angle/2)\n",
    "\n",
    "    desired_direction = lab.utils.quat_mul_vec(controller_orient, np.array([0,0,1], dtype=np.float32))\n",
    "    \n",
    "    # compute the n closest\n",
    "    indices, weights = get_k_neighbors(current_x, current_v, K_NEIGHBORS)\n",
    "    #display(indices)\n",
    "\n",
    "    rewards = np.zeros(K_NEIGHBORS)\n",
    "    for n_idx in range(K_NEIGHBORS):\n",
    "\n",
    "        w = weights.copy()\n",
    "        w[n_idx] = 1.0\n",
    "        w /= np.sum(w)\n",
    "        nx, nv = compute_new_state(current_x, indices, w, TUG_RATIO)\n",
    "\n",
    "        reward = action_reward(desired_direction, current_x, nx)\n",
    "\n",
    "        # store the rewards\n",
    "        rewards[n_idx] = reward\n",
    "\n",
    "    # apply the best\n",
    "    display(rewards)\n",
    "    best_i = np.argmax(rewards)\n",
    "    weights[best_i] = 1.0\n",
    "    weights /= np.sum(weights)\n",
    "    current_x[...], current_v[...] = compute_new_state(current_x, indices, weights, TUG_RATIO)\n",
    "    \n",
    "    q, p = pose_to_qp(current_x)\n",
    "\n",
    "    if on_spot:\n",
    "        p[0] = [0, 0, 200]\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "\n",
    "    character.materials()[0].set_albedo(np.array([.4, .4, .8], dtype=np.float32))\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    d = lab.utils.quat_to_mat(controller_orient, p[0])\n",
    "    viewer.draw(displacement_asset, d)\n",
    "\n",
    "    for i in range(K_NEIGHBORS):\n",
    "      \n",
    "        q, p = pose_to_qp(states_x[indices[i]])\n",
    "        a = lab.utils.quat_to_mat(q, p)\n",
    "        character.materials()[0].set_albedo(np.ones(3, dtype=np.float32) * float(weights[i]))\n",
    "        if i == best_i:\n",
    "            character.materials()[0].set_albedo(np.array([0,1,0], dtype=np.float32))\n",
    "        a[0, 0, 3] = i * 40\n",
    "        viewer.draw(character, a)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=widgets.Play(interval=1000./30.), #lab.Timeline(max=100),\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e9332-cbc4-4f24-b848-fe30c8d58fb9",
   "metadata": {},
   "source": [
    "# Using the value function\n",
    "\n",
    "The value function provides a smooth estimate of the future reward from any possible state.  \n",
    "\n",
    "\n",
    "\n",
    "**What is a state?**  \n",
    "A state in the motion field is not only the physical **motion state** $m = (x,v)$ (pose + velocity), but also includes the **task goal parameters** $\\theta_T$.  \n",
    "Thus, a full task state is\n",
    "$$\n",
    "s = (m, \\theta_T).\n",
    "$$\n",
    "\n",
    "- $x$: joint configuration (root position + joint orientations)  \n",
    "- $v$: finite-difference velocity  \n",
    "- $\\theta_T$: high-level control parameters (e.g. desired direction, target location)\n",
    "\n",
    "\n",
    "\n",
    "**How is the value function stored?**  \n",
    "- We store one scalar $V(s)$ for every database state $s$.  \n",
    "- These stored values form anchor points scattered throughout the motion field.  \n",
    "- Because of the dense motion data and interpolation, the value function behaves as if it were continuous, even though it is only sampled at discrete states.\n",
    "\n",
    "\n",
    "\n",
    "**How do we read future values?**  \n",
    "When we take an action $a$ from a state $s$:\n",
    "\n",
    "1. Integrate one step forward to obtain the predicted next state:\n",
    "   $$\n",
    "   s' = I_s(s,a).\n",
    "   $$\n",
    "\n",
    "2. Perform a k-NN search around $s'$ to find the closest database states $\\{s_j\\}$.\n",
    "\n",
    "3. Compute similarity weights:\n",
    "   $$\n",
    "   \\omega_j = \\frac{1/d(s',s_j)^2}{\\sum_{\\ell} 1/d(s',s_\\ell)^2}.\n",
    "   $$\n",
    "\n",
    "4. Interpolate the stored values:\n",
    "   $$\n",
    "   V(s') \\;\\approx\\; \\sum_j \\omega_j \\, V(s_j).\n",
    "   $$\n",
    "\n",
    "\n",
    "\n",
    "**Key idea**  \n",
    "Even though we only store values at the discrete database states, k-NN interpolation with similarity weights makes the value function **continuous across the motion field**.  \n",
    "This means we can evaluate the long-term utility of any new, unseen state by smoothly blending the values of its nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc637ad-006b-46c0-a0dd-5b6400d5611b",
   "metadata": {},
   "source": [
    "---\n",
    "### Fitted value function training\n",
    "\n",
    "\n",
    "**Step 1: Initialize values**  \n",
    "For each database motion state $s$, we store a value\n",
    "$$\n",
    "V(s) \\in \\mathbb{R}.\n",
    "$$\n",
    "Initially, all values are set to zero.\n",
    "\n",
    "\n",
    "**Step 2: Action rollout via k-NN**  \n",
    "Compute the reward for each of the k actions>\n",
    "\n",
    "\n",
    "**Step 3: Bellman update**  \n",
    "For each database state $m$, update its value using the Bellman equation:\n",
    "$$\n",
    "V(m) \\;\\leftarrow\\; \\max_{a \\in A(s)} \\Big[ R(s,a) \\;+\\; \\gamma \\sum_j \\omega_j V(s_j') \\Big],\n",
    "$$\n",
    "where\n",
    "- $R(m,a)$ is the immediate reward for taking action $a$ at state $s$,\n",
    "- $\\gamma \\in (0,1)$ is the discount factor.\n",
    "\n",
    "\n",
    "**Step 4: Iterate to convergence**  \n",
    "Repeat the update across all states until the value function stabilizes.  \n",
    "The result is a smooth value landscape over the motion field, enabling policies that anticipate future rewards rather than acting greedily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165b58f-ac77-444e-aced-2848b16204b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "progress_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "display(progress_output)\n",
    "\n",
    "# precompute all the states field transitions\n",
    "K_NEIGHBORS = 15\n",
    "TUG_RATIO_LEARNING = .1\n",
    "\n",
    "all_states_actions_states_x = np.zeros((states_count, K_NEIGHBORS, bone_count+2, 4), dtype=np.float32)\n",
    "all_states_actions_states_v = np.zeros((states_count, K_NEIGHBORS, bone_count+2, 4), dtype=np.float32)\n",
    "\n",
    "all_states_actions_value_function_indices = np.zeros((states_count, K_NEIGHBORS, K_NEIGHBORS), dtype=np.int16)\n",
    "all_states_actions_value_function_weights = np.zeros((states_count, K_NEIGHBORS, K_NEIGHBORS), dtype=np.float32)\n",
    "\n",
    "def _build_precomputed_tables():\n",
    "\n",
    "    with progress_output:\n",
    "\n",
    "        display(f\"get all future indices and weights\")\n",
    "        batched_query = np.zeros([K_NEIGHBORS, FEATURE_SHAPE[0], 3], dtype=np.float32)\n",
    "        future_indices, future_weights = get_batched_k_neighbors(metric_matrix, K_NEIGHBORS)\n",
    "        \n",
    "        for i in range(states_count):\n",
    "    \n",
    "            progress_output.clear_output()\n",
    "            display(f\"state {i+1} / {states_count}\")\n",
    "        \n",
    "            indices, weights = future_indices[i], future_weights[i]\n",
    "\n",
    "            for n_idx in range(K_NEIGHBORS):\n",
    "                w = weights.copy()\n",
    "                w[n_idx] = 1.0\n",
    "                w /= np.sum(w)\n",
    "\n",
    "                # compute the next state, and see how much it rotates\n",
    "                all_states_actions_states_x[i, n_idx, ...], all_states_actions_states_v[i, n_idx, ...] = compute_new_state(states_x[i], indices, w, TUG_RATIO_LEARNING)\n",
    "                batched_query[n_idx, ...] = build_distance_metric(all_states_actions_states_x[i, n_idx, ...], all_states_actions_states_v[i, n_idx, ...])\n",
    "        \n",
    "            # find the next next\n",
    "            all_states_actions_value_function_indices[i, :, :], all_states_actions_value_function_weights[i, :, :] = get_batched_k_neighbors(batched_query, K_NEIGHBORS)\n",
    "\n",
    "\n",
    "    with open('motion_fields_precomputed_all_states_tables.dat', 'wb') as f:\n",
    "        pickle.dump((all_states_actions_states_x, all_states_actions_states_v, all_states_actions_value_function_indices, all_states_actions_value_function_weights), f)\n",
    "\n",
    "#_build_precomputed_tables()\n",
    "with open('motion_fields_precomputed_all_states_tables.dat', 'rb') as f:\n",
    "    (all_states_actions_states_x, all_states_actions_states_v, all_states_actions_value_function_indices, all_states_actions_value_function_weights) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a99dab8-49a5-423e-9443-56875c6334cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the task goals\n",
    "\n",
    "theta_count = 17\n",
    "thetas = np.linspace(-np.pi, np.pi, theta_count+1)[:theta_count]\n",
    "theta_spacing = 2*np.pi / theta_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94fe68-8f8b-44b1-a2cb-8cd2435842ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the value function using Pytorch\n",
    "\n",
    "EPOCH = 300\n",
    "gamma = .99\n",
    "pi = torch.pi\n",
    "\n",
    "def _train(is_walking, factor):\n",
    "    # output\n",
    "    scores = torch.zeros([EPOCH, 3])\n",
    "    V = torch.zeros([states_count, theta_count], device='cuda')\n",
    "    \n",
    "    # transfer to GPU\n",
    "    tensor_all_states_action_delta_root_quat = torch.tensor(all_states_actions_states_x[:, :, 2, :], device='cuda')\n",
    "    tensor_all_states_actions_value_function_indices = torch.tensor(all_states_actions_value_function_indices, device='cuda')\n",
    "    tensor_all_states_actions_value_function_weights = torch.tensor(all_states_actions_value_function_weights, device='cuda')\n",
    "    theta_grid = torch.tensor(thetas, device='cuda')\n",
    "\n",
    "    # compute delta orientation\n",
    "    delta_orientation = torch.atan2(2. * tensor_all_states_action_delta_root_quat[..., 0] * tensor_all_states_action_delta_root_quat[..., 2], 1.0 - 2. * tensor_all_states_action_delta_root_quat[...,2]**2.)\n",
    "\n",
    "    # unused later\n",
    "    del tensor_all_states_action_delta_root_quat\n",
    "\n",
    "    # flag locomotion types\n",
    "    state_score = torch.zeros([states_count], device='cuda')\n",
    "    if is_walking:\n",
    "        state_score[:end_of_walk_ids] = 1\n",
    "    else:\n",
    "        state_score[end_of_walk_ids:] = 1\n",
    "    \n",
    "    \n",
    "    # compute rewards\n",
    "    expand_theta_grid = theta_grid.view(1, 1, theta_count) #per state, per action, each theta\n",
    "    \n",
    "    expand_delta_orientation = delta_orientation.view(states_count, K_NEIGHBORS, 1)\n",
    "    next_orientation = expand_theta_grid + expand_delta_orientation  # braodcast S, A, T\n",
    "    next_orientation = (next_orientation + pi) % (2.0*pi) - pi\n",
    "    \n",
    "    rewards = -torch.abs(next_orientation) + state_score.unsqueeze(-1).unsqueeze(-1) * factor\n",
    "\n",
    "    # compute accessors for interpolations\n",
    "    step = (2*pi)/theta_count\n",
    "    coord = (next_orientation +pi) / step                          # (S,A,T)\n",
    "    i0 = torch.floor(coord).to(torch.long) % theta_count           # lower index\n",
    "    i1 = (i0 + 1) % theta_count                                    # upper index\n",
    "    alpha  = coord - torch.floor(coord)                            # weight to upper (in [0,1))\n",
    "    \n",
    "    i0_exp = i0.unsqueeze(2).expand(-1, -1, K_NEIGHBORS, -1)\n",
    "    i1_exp = i1.unsqueeze(2).expand(-1, -1, K_NEIGHBORS, -1)\n",
    "\n",
    "    # train\n",
    "    for epoch in range(EPOCH):\n",
    "        V_neighbors = V[tensor_all_states_actions_value_function_indices.to(torch.long)]\n",
    "        \n",
    "        V0 = torch.gather(V_neighbors, 3, i0_exp)\n",
    "        V1 = torch.gather(V_neighbors, 3, i1_exp)\n",
    "        \n",
    "        # Task interpolation then motion interpolation:\n",
    "        V_task = (1.0 - alpha).unsqueeze(2) * V0 + alpha.unsqueeze(2) * V1  # (S,A,J,Tθ)\n",
    "        \n",
    "        exp_next_V = (V_task * tensor_all_states_actions_value_function_weights.unsqueeze(-1)).sum(dim=2)     # (S,A,Tθ)\n",
    "        \n",
    "        # Bellman backup, then max over actions:\n",
    "        Q = rewards + gamma * exp_next_V                            # (S,A,Tθ)\n",
    "        V_prime = Q.max(dim=1).values                                 # (S,Tθ)\n",
    "        \n",
    "        bellman_residual = torch.abs(V-V_prime)\n",
    "        scores[epoch, 0] = bellman_residual.min()\n",
    "        scores[epoch, 1] = bellman_residual.max()\n",
    "        scores[epoch, 2] = bellman_residual.mean()\n",
    "        V = V_prime\n",
    "    return V.cpu().numpy(), scores\n",
    "    \n",
    "value_function_walk, scores = _train(True, 1)\n",
    "value_function_jog, scores = _train(False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659e65a-c4ae-491a-b68b-a3f138ff269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(EPOCH)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "\n",
    "# First subplot\n",
    "axs.plot(x, scores[:, 2], label='Mean', color='blue')\n",
    "axs.fill_between(x, scores[:, 0], scores[:, 1], color='lightblue', alpha=0.4, label='Min-Max Range')\n",
    "axs.set_title('Scores over Epoch (Mean and Range)')\n",
    "axs.set_ylabel('Value')\n",
    "axs.legend()\n",
    "axs.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281ecfb-bff7-4ee4-aa04-c9c8edf66140",
   "metadata": {},
   "source": [
    "### Motion Fields\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d18d270-21fa-4f57-ad5e-4f4969193929",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indice = 0\n",
    "\n",
    "\n",
    "current_x = states_x[last_indice, ...].copy()\n",
    "current_v = states_v[last_indice, ...].copy()\n",
    "q, p = pose_to_qp(current_x)\n",
    "q, p = lab.utils.quat_fk(q, p, parents)\n",
    "toes_positions = p[[bones.index('LeftToe'), bones.index('LeftToe')], ...]\n",
    "toes_ratio = [0, 0]\n",
    "\n",
    "\n",
    "def compute_theta_blend_factors(theta_prime):\n",
    "    # find the rotation indices\n",
    "    lower_id = int((theta_prime + np.pi) / theta_spacing)  % theta_count\n",
    "    upper_id = (lower_id + 1) % theta_count\n",
    "    theta_lower = theta_spacing*lower_id - np.pi\n",
    "    angle_offset = (theta_prime - theta_lower + 2 * np.pi) % (2 * np.pi)\n",
    "    t = angle_offset / theta_spacing\n",
    "\n",
    "    return lower_id, upper_id, t\n",
    "\n",
    "\n",
    "def render(frame, on_spot=False, display_debug=False):\n",
    "\n",
    "    controller_dir = np.array([1,0,0,0], dtype=np.float32)\n",
    "    posx = gamepad.axes[0].value \n",
    "    posz = -gamepad.axes[1].value \n",
    "    if np.abs(posx) > 0.001 or np.abs(posz) > 0.001:\n",
    "        angle = np.atan2(posz, posx)\n",
    "        controller_dir[0] = np.cos(angle/2)\n",
    "        controller_dir[2] = np.sin(angle/2)\n",
    "\n",
    "    color = np.array([1,1,0], dtype=np.float32)\n",
    "    value_function = value_function_walk\n",
    "    if gamepad.buttons[1].value > 0.5:\n",
    "        color = np.array([1,0,1], dtype=np.float32)\n",
    "        value_function = value_function_jog\n",
    "\n",
    "    desired_direction = lab.utils.quat_mul_vec(controller_dir, np.array([0,0,1], dtype=np.float32))\n",
    "\n",
    "    if gamepad.buttons[0].value > 0.5 :\n",
    "        rot = lab.utils.angle_axis_to_quat(.2, np.array([0,0,-1]))\n",
    "        current_v[bones.index('Spine')+2] = lab.utils.quat_mul(rot, current_v[bones.index('Spine')+2])\n",
    "        current_v[bones.index('Spine1')+2] = lab.utils.quat_mul(rot, current_v[bones.index('Spine1')+2])\n",
    "        current_v[bones.index('Spine2')+2] = lab.utils.quat_mul(rot, current_v[bones.index('Spine2')+2])\n",
    "        current_v[1, :3] += lab.utils.quat_mul_vec(current_v[2], np.array([0,0,-10]))\n",
    "\n",
    "        current_x[bones.index('Spine')+2] = lab.utils.quat_mul(rot, current_x[bones.index('Spine')+2])\n",
    "        current_x[bones.index('Spine1')+2] = lab.utils.quat_mul(rot, current_x[bones.index('Spine1')+2])\n",
    "        current_x[bones.index('Spine2')+2] = lab.utils.quat_mul(rot, current_x[bones.index('Spine2')+2])\n",
    "        current_x[1, :3] += lab.utils.quat_mul_vec(current_v[2], np.array([0,0,-10]))\n",
    "\n",
    "    \n",
    "    # compute the n closest\n",
    "    indices, weights = get_k_neighbors(current_x, current_v, K_NEIGHBORS)\n",
    "\n",
    "    # get all the possible actions to query\n",
    "    batched_query = np.zeros([K_NEIGHBORS, FEATURE_SHAPE[0], 3], dtype=np.float32)\n",
    "    batched_theta_prime = np.zeros([K_NEIGHBORS], dtype=np.float32)\n",
    "    for n_idx in range(K_NEIGHBORS):\n",
    "        w = weights.copy()\n",
    "        w[n_idx] = 1.0\n",
    "        w /= np.sum(w)\n",
    "    \n",
    "        # compute the next state, and see how much it rotates\n",
    "        x, v = compute_new_state(current_x, indices, w, TUG_RATIO_LEARNING)\n",
    "        n = pose_unpack(x)\n",
    "        batched_query[n_idx, ...] = build_distance_metric(x, v)\n",
    "    \n",
    "        orientation = lab.utils.quat_mul_vec(n.quats[0], np.array([0,0,1], dtype=np.float32))\n",
    "        batched_theta_prime[n_idx] = signed_angle(orientation, desired_direction)\n",
    "\n",
    "    next_indices, next_weights = get_batched_k_neighbors(batched_query, K_NEIGHBORS)\n",
    "\n",
    "    future_rewards = np.zeros(K_NEIGHBORS)\n",
    "    for n_idx in range(K_NEIGHBORS):\n",
    "\n",
    "        # find the indices for the future\n",
    "        theta_prime = batched_theta_prime[n_idx]\n",
    "        d_lower_id, d_upper_id, d_t = compute_theta_blend_factors(theta_prime)\n",
    "\n",
    "        #compute future value\n",
    "        dl = np.sum( value_function[next_indices[n_idx], d_lower_id] * next_weights[n_idx])\n",
    "        du = np.sum( value_function[next_indices[n_idx], d_upper_id] * next_weights[n_idx])\n",
    "\n",
    "        future_reward = (1.0-d_t) * dl + d_t * du\n",
    "\n",
    "        # store the rewards\n",
    "        future_rewards[n_idx] = future_reward\n",
    "\n",
    "    # apply the best\n",
    "    best_i = np.argmax(future_rewards)\n",
    "    weights[best_i] = 1.0\n",
    "    weights /= np.sum(weights)\n",
    "    current_x[...], current_v[...] = compute_new_state(current_x, indices, weights, .1)\n",
    "    \n",
    "    lock = np.sum(states_c[indices] * weights[:, None], axis=0 )\n",
    "\n",
    "    # if display_debug:\n",
    "    #     display((indices, future_rewards, best_i))\n",
    "    \n",
    "    q, p = pose_to_qp(current_x)\n",
    "\n",
    "    gq, gp = lab.utils.quat_fk(q, p, parents)\n",
    "    left_foot_p_current = gp[bones.index('LeftToe')]\n",
    "    right_foot_p_current = gp[bones.index('RightToe')]\n",
    "\n",
    "    if lock[0] < 0.9 :\n",
    "        toes_ratio[0] = min(1.0, toes_ratio[0] + 0.2)\n",
    "        toes_positions[0, ...] = toes_positions[0, ...] * (1.0-toes_ratio[0]) + left_foot_p_current * toes_ratio[0]\n",
    "    else :\n",
    "        toes_ratio[0] = 0\n",
    "    if lock[1] < 0.9 :\n",
    "        toes_ratio[1] = min(1.0, toes_ratio[1] + 0.2)\n",
    "        toes_positions[1, ...] = toes_positions[1, ...] * (1.0-toes_ratio[1]) + right_foot_p_current * toes_ratio[1]\n",
    "    else:\n",
    "        toes_ratio[1] = 0\n",
    "\n",
    "    id_toes = [bones.index('LeftToe'), bones.index('RightToe')]\n",
    "    id_feet = [bones.index('LeftFoot'), bones.index('RightFoot')]\n",
    "    relative_foot = lab.utils.qp_mul(lab.utils.qp_inv((gq[id_toes], gp[id_toes])), ((gq[id_feet], gp[id_feet])))\n",
    "    new_foot = lab.utils.qp_mul((gq[id_toes], toes_positions), relative_foot)\n",
    "\n",
    "    q, p = lab.utils.limb_ik(q[None,...], p[None,...], parents, bones, new_foot[0][None,...], new_foot[1][None,...] )\n",
    "    q = q[0]\n",
    "    p = p[0]\n",
    "    \n",
    "    if on_spot:\n",
    "        p[0] = [0, 0, 200]\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "\n",
    "    character.materials()[0].set_albedo(np.array([.4, .4, .8], dtype=np.float32))\n",
    "    displacement_asset.materials()[0].set_albedo(color)\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    d = lab.utils.quat_to_mat(controller_dir, p[0])\n",
    "    viewer.draw(displacement_asset, d)\n",
    "\n",
    "    if display_debug:\n",
    "        for i in range(K_NEIGHBORS):\n",
    "            q, p = pose_to_qp(states_x[indices[i]])\n",
    "            a = lab.utils.quat_to_mat(q, p)\n",
    "            character.materials()[0].set_albedo(np.ones(3, dtype=np.float32) * float(weights[i]))\n",
    "            a[0, 0, 3] = i * 40\n",
    "            viewer.draw(character, a)\n",
    "        \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=widgets.Play(interval=1000./5.), #lab.Timeline(max=100),\n",
    ")\n",
    "viewer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
