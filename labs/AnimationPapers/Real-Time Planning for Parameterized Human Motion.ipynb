{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3970e57f-0002-4c8a-a3f4-f71537a277d7",
   "metadata": {},
   "source": [
    "# Real-Time Planning for Parameterized Human Motion\n",
    "\n",
    "by Wan-Yen Lo and Matthias Zwicker\n",
    "2008\n",
    "\n",
    "Notebook by Jerome Eippers, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951d8ae-84c9-4810-8814-d88702f7e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pickle\n",
    "from random import randrange\n",
    "from random import uniform\n",
    "import numpy as np\n",
    "from ipywidgets import widgets, interact\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as plt_color\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import ipyanimlab as lab\n",
    "\n",
    "viewer = lab.Viewer(move_speed=5, width=1280, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e0f36-6435-4962-9bef-baaf1ae6170b",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8353f4-8984-48e1-a851-bc64b54e178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the character\n",
    "character = viewer.import_usd_asset('AnimLabSimpleMale.usd')\n",
    "character.add_bone('LeftHeel', np.array([1,0,0,0]), np.array([9.2,0,-12]), 'LeftFoot')\n",
    "character.add_bone('LeftBall', np.array([1,0,0,0]), np.array([14.5,0,8.22]), 'LeftFoot')\n",
    "character.add_bone('RightHeel', np.array([1,0,0,0]), np.array([-9.2,0,-12]), 'RightFoot')\n",
    "character.add_bone('RightBall', np.array([1,0,0,0]), np.array([-14.5,0,8.22]), 'RightFoot')\n",
    "\n",
    "left_heel = character.bone_index('LeftHeel')\n",
    "left_ball = character.bone_index('LeftBall')\n",
    "right_heel = character.bone_index('RightHeel')\n",
    "right_ball = character.bone_index('RightBall')\n",
    "left_foot = character.bone_index('LeftFoot')\n",
    "right_foot = character.bone_index('RightFoot')\n",
    "left_toe = character.bone_index('LeftToe')\n",
    "right_toe = character.bone_index('RightToe')\n",
    "foottag_indices = np.asarray([left_heel, left_ball, right_heel, right_ball], dtype=np.int8)\n",
    "print(foottag_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48a9e7-c7f6-4e4b-9807-3b0d944bedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction = viewer.import_usd_asset('../../meshes/displacement.usd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db52b0-1c40-49aa-84c9-d3d5b750e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = viewer.create_asset(\n",
    "    vertices = np.asarray([[9.37, 0.58, -6.81, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [3.58, 0.58, -11.01, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [-3.58, 0.58, -11.01, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [-9.37, 0.58, -6.81, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [-11.58, 0.58, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [-9.37, 0.58, 6.81, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [-3.58, 0.58, 11.01, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [3.58, 0.58, 11.01, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [9.37, 0.58, 6.81, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [11.58, 0.58, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0], [0.0, 0.58, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]], dtype=np.float32),\n",
    "    indices = np.asarray([[1, 2, 10], [3, 4, 10], [5, 6, 10], [7, 8, 10], [9, 0, 10]], dtype=np.int16)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b061225",
   "metadata": {},
   "source": [
    "## Animation Data Source\n",
    "The animation data used in this notebook was generated using [Motorica.ai](https://motorica.ai).  \n",
    "Please note that this data is provided under Motoricaâ€™s [Terms of Service](https://motorica2024.webflow.io/terms-of-service).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d3fa4-ece0-4051-bda0-5b228288a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('realtime_planning_animations_data.bin', 'rb') as f:\n",
    "    animations_matrices_datas, anim_bones = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0acb90b-a5f8-4ba5-80cd-4afd5debebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "animmap = lab.AnimMapper(character, root_motion=True, match_effectors=False)\n",
    "animations = []\n",
    "\n",
    "for matrices_anim, left_clip, right_clip in animations_matrices_datas:\n",
    "    q, p = lab.utils.m4x4_to_qp(matrices_anim)\n",
    "    anim = lab.Anim(q, p, p[0], None, anim_bones)\n",
    "    anim = animmap(anim)\n",
    "    animations.append(anim)\n",
    "\n",
    "bone_count = character.bone_count()\n",
    "bones = animations[0].bones\n",
    "parents = animations[0].parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb0a17-4310-4655-8736-05b6917556b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, index=0):\n",
    "\n",
    "    frame = min(frame, animations[index].quats.shape[0] -1)\n",
    "    q = (animations[index].quats[frame,...])\n",
    "    p = (animations[index].pos[frame,...])\n",
    "        \n",
    "    a =  lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "   \n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=100),\n",
    "    index=widgets.IntSlider(max=len(animations)-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c64ea-cc99-490f-806a-38ace7a45077",
   "metadata": {},
   "source": [
    "* 0 -> 9 - walks curved\n",
    "* 10 -> 23 - turns\n",
    "* 24 - walk straight  \n",
    "* 25 - start  \n",
    "* 26 - stop  \n",
    "* 27 - stop  \n",
    "* 28 - stop  \n",
    "* 29 - walk real slow  \n",
    "* 30 - walk slow  \n",
    "* 31 -> 46 -  stop  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d3aaa-0784-4359-b93a-66d5d5f94817",
   "metadata": {},
   "source": [
    "## Motion Model: Motion Clips\n",
    "\n",
    "In this notebook, human motion is modeled as a collection of **short motion clips**, where **each clip represents a single walking step**.  \n",
    "This design follows the approach in *near-optimal character animation with continous control (2007)*.\n",
    "\n",
    "Each step is extracted from motion capture data and organized so that the clips can be **sequenced and blended** to form continuous locomotion.\n",
    "\n",
    "### Foot Contact Alignment\n",
    "\n",
    "To ensure **realistic and smooth transitions** between steps, each clip is **temporally aligned** at the foot contact frames.  \n",
    "This means the end of one step naturally matches the beginning of the next, minimizing foot sliding or artifacts when clips are concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e119d2-2eba-4789-9401-95fbc1fe5380",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_STEP_LEN = 64\n",
    "LEFT_CLIP_COUNT = sum((len(left_clip) for matrices_anim, left_clip, right_clip in animations_matrices_datas))\n",
    "RIGHT_CLIP_COUNT = sum((len(right_clip) for matrices_anim, left_clip, right_clip in animations_matrices_datas))\n",
    "CLIP_COUNT = LEFT_CLIP_COUNT + RIGHT_CLIP_COUNT\n",
    "CLIP_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1c7d0-3ffd-4314-826f-8d6c64033898",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_q = np.array([1,0,0,0], dtype=np.float32)[np.newaxis,...].repeat(CLIP_COUNT * MAX_STEP_LEN * bone_count, axis=0).reshape(CLIP_COUNT, MAX_STEP_LEN, bone_count, 4)\n",
    "clips_p = np.array([0,0,0], dtype=np.float32).repeat(CLIP_COUNT* MAX_STEP_LEN * bone_count).reshape(CLIP_COUNT, MAX_STEP_LEN, bone_count, 3)\n",
    "clips_timings = np.zeros([CLIP_COUNT, 5], dtype=np.uint32)\n",
    "clips_sources = np.zeros([CLIP_COUNT], dtype=np.uint32)\n",
    "clips_sides = np.zeros([CLIP_COUNT], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24956090-1ecb-42d6-9efd-4946efd3f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_root(q, p):\n",
    "    g_q, g_p = lab.utils.quat_fk(q, p, animations[0].parents)\n",
    "    v = lab.utils.quat_mul_vec(g_q[:, character.bone_index('Hips'), :], np.array([0,1,0]))\n",
    "    #v = g_p[:, character.bone_index('RightHand'), :] - g_p[:, character.bone_index('Spine2'), :]\n",
    "    angle = np.atan2(v[:, 0], v[:, 2])\n",
    "    g_q[:, 0, 0] = np.cos(angle/2)\n",
    "    g_q[:, 0, 2] = np.sin(angle/2)\n",
    "    q, p = lab.utils.quat_ik(g_q, g_p, animations[0].parents)\n",
    "    q[:, 0, :], p[:, 0, :] = lab.utils.qp_mul(lab.utils.qp_inv((q[0:1, 0, :], p[0:1, 0, :])), (q[:, 0, :], p[:, 0, :]))\n",
    "    return q, p\n",
    "\n",
    "def compute_clip(quats, pos, ranges):\n",
    "      \n",
    "    aq = quats[ranges[0]:ranges[4],...].copy()\n",
    "    ap = pos[ranges[0]:ranges[4],...].copy()\n",
    "\n",
    "    q = np.array([1,0,0,0], dtype=np.float32)[np.newaxis,...].repeat(MAX_STEP_LEN * bone_count, axis=0).reshape(MAX_STEP_LEN, bone_count, 4)\n",
    "    p = np.array([0,0,0], dtype=np.float32).repeat(MAX_STEP_LEN * bone_count).reshape(MAX_STEP_LEN, bone_count, 3)\n",
    "\n",
    "    q[:aq.shape[0], ...] = aq\n",
    "    p[:ap.shape[0], ...] = ap\n",
    "    \n",
    "    iq, ip = lab.utils.qp_inv((q[0,0], p[0,0]))\n",
    "    \n",
    "    q[:,0], p[:,0] = lab.utils.qp_mul(\n",
    "        (iq[np.newaxis,...], ip[np.newaxis,...]),\n",
    "        (q[:,0],p[:,0])\n",
    "    )\n",
    "\n",
    "    return compute_root(q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4766d-5922-456f-9f0d-ad9e75bf143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_clip_count = 0\n",
    "right_clip_count = 0\n",
    "\n",
    "for i in range(len(animations)):\n",
    "    quats, pos = animations[i].quats.copy(), animations[i].pos.copy()\n",
    "    _, l_ranges, r_ranges = animations_matrices_datas[i]\n",
    "    \n",
    "    for ranges in l_ranges:\n",
    "        ranges = np.array(ranges, dtype=np.uint32)\n",
    "        left_anim = compute_clip(quats, pos, ranges)\n",
    "        clips_q[left_clip_count, ...], clips_p[left_clip_count, ...] = left_anim\n",
    "        clips_timings[left_clip_count, 4] = ranges[0]\n",
    "        clips_timings[left_clip_count, :4] = ranges[1:] - ranges[0]\n",
    "        clips_sources[left_clip_count] = i\n",
    "        clips_sides[left_clip_count] = 0\n",
    "        left_clip_count += 1\n",
    "           \n",
    "    for ranges in r_ranges:\n",
    "        ranges = np.array(ranges, dtype=np.uint32)\n",
    "        right_anim = compute_clip(quats, pos, ranges)\n",
    "        clips_q[right_clip_count + LEFT_CLIP_COUNT, ...], clips_p[right_clip_count + LEFT_CLIP_COUNT, ...] = right_anim\n",
    "        clips_timings[right_clip_count + LEFT_CLIP_COUNT, 4] = ranges[0]\n",
    "        clips_timings[right_clip_count + LEFT_CLIP_COUNT, :4] = ranges[1:] - ranges[0]\n",
    "        clips_sources[right_clip_count + LEFT_CLIP_COUNT] = i\n",
    "        clips_sides[right_clip_count + LEFT_CLIP_COUNT] = 1\n",
    "        right_clip_count += 1\n",
    "\n",
    "clips_q = lab.utils.remove_quat_discontinuities(clips_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d349b-a1a1-42a8-9c99-40a1d0c329de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_constraint_qp(gpos, frame, foot_id, toe_id):\n",
    "    vec = gpos[frame, toe_id, :] - gpos[frame, foot_id, :]\n",
    "    angle = np.arctan2(vec[0], vec[2])/2\n",
    "    q = np.zeros(4, dtype=np.float32)\n",
    "    p = np.zeros(3, dtype=np.float32)\n",
    "    q[0] = np.cos(angle)\n",
    "    q[2] = np.sin(angle)\n",
    "    p[[0,2]] = gpos[frame, foot_id, [0,2]]\n",
    "    return q, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a7643-84d7-47eb-88aa-7f6f0616b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionClip:\n",
    "    def __init__(self, clip_id):\n",
    "        self._id = clip_id\n",
    "        self.timings = clips_timings[clip_id, :4]\n",
    "        self.quats = clips_q[clip_id, ...]\n",
    "        self.pos = clips_p[clip_id, ...]\n",
    "        self.side = clips_sides[clip_id]\n",
    "\n",
    "        self.constraints_q = np.zeros([2, 4], dtype=np.float32)\n",
    "        self.constraints_p = np.zeros([2, 3], dtype=np.float32)\n",
    "\n",
    "        self.delta_theta = np.atan2(\n",
    "            2 * self.quats[self.timings[1], 0, 0] * self.quats[self.timings[1], 0, 2], \n",
    "            1.0 - (2 * self.quats[self.timings[1], 0, 2] * self.quats[self.timings[1], 0, 2])\n",
    "        )\n",
    "\n",
    "        _, gpos = lab.utils.quat_fk(self.quats, self.pos, animations[0].parents)\n",
    "        if self.side == 0:\n",
    "            self.constraints_q[0, :], self.constraints_p[0, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[0],\n",
    "                foottag_indices[0],\n",
    "                foottag_indices[1]\n",
    "            )\n",
    "            self.constraints_q[1, :], self.constraints_p[1, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[2],\n",
    "                foottag_indices[2],\n",
    "                foottag_indices[3]\n",
    "            )\n",
    "        else:\n",
    "            self.constraints_q[0, :], self.constraints_p[0, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[0],\n",
    "                foottag_indices[2],\n",
    "                foottag_indices[3]\n",
    "            )\n",
    "            self.constraints_q[1, :], self.constraints_p[1, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[2],\n",
    "                foottag_indices[0],\n",
    "                foottag_indices[1]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145460ae-e9e9-4c6d-90a9-d65b8a458431",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_clips = [MotionClip(i) for i in range(CLIP_COUNT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac76e51-a736-468e-84bd-ee535b1ceb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, clip_id=0):\n",
    "\n",
    "    q = motion_clips[clip_id].quats[frame].copy()\n",
    "    p = motion_clips[clip_id].pos[frame].copy()\n",
    "    \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    contacts_matrices = np.eye(4, dtype=np.float32)[np.newaxis,...].repeat(2, axis=0)\n",
    "    contacts_matrices = lab.utils.quat_to_mat( motion_clips[clip_id].constraints_q,  motion_clips[clip_id].constraints_p )\n",
    "\n",
    "    viewer.draw(target, contacts_matrices)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.draw_axis(contacts_matrices, 20)\n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    display(motion_clips[clip_id].timings)\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1),\n",
    "    clip_id=widgets.IntSlider(max=CLIP_COUNT-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1919b4-1e6f-4771-bbdc-c21f48ad4336",
   "metadata": {},
   "source": [
    "## Player\n",
    "\n",
    "Let's have a player that can play animations and blend clips together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259c235-8865-4c8b-8dfb-eb6cba0225f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipPlayer:\n",
    "    def __init__(self, motion):\n",
    "        self.motion = motion\n",
    "        self.frame = -1\n",
    "        self.start_at_out_frame = 0\n",
    "        self.start_clip_frame = 0\n",
    "        self.blend_in_frame_count = 0\n",
    "        self.quaternions = motion.quats.copy()\n",
    "        self.positions = motion.pos.copy()      \n",
    "        \n",
    "    def align_to_out(self, out_clip):\n",
    "        pre_contact_blend_time = min(out_clip.motion.timings[ 2] - out_clip.motion.timings[ 1], self.motion.timings[ 0])\n",
    "        post_contact_blend_time = min(out_clip.motion.timings[ 3] - out_clip.motion.timings[ 2], self.motion.timings[ 1] - self.motion.timings[ 0])\n",
    "        \n",
    "        self.start_at_out_frame = out_clip.motion.timings[ 2] - pre_contact_blend_time\n",
    "        self.start_clip_frame = self.motion.timings[ 0] - pre_contact_blend_time\n",
    "        self.blend_in_frame_count = pre_contact_blend_time + post_contact_blend_time\n",
    "        self.frame = self.start_clip_frame\n",
    "\n",
    "        #align motion\n",
    "        iq, ip = lab.utils.qp_inv((self.motion.constraints_q[ 0], self.motion.constraints_p[ 0]))\n",
    "        self.quaternions[:,0], self.positions[:,0] = lab.utils.qp_mul(\n",
    "            (iq[np.newaxis,...], ip[np.newaxis,...]),\n",
    "            (self.quaternions[:,0],self.positions[:,0])\n",
    "        )\n",
    "        q, p = lab.utils.qp_mul(\n",
    "            (out_clip.quaternions[0, 0], out_clip.positions[0, 0]),\n",
    "            (out_clip.motion.constraints_q[ 1], out_clip.motion.constraints_p[ 1]),\n",
    "        )\n",
    "        self.quaternions[:,0], self.positions[:,0] = lab.utils.qp_mul(\n",
    "            (q[np.newaxis,...], p[np.newaxis,...]),\n",
    "            (self.quaternions[:,0],self.positions[:,0])\n",
    "        )\n",
    "        \n",
    "\n",
    "    def tick(self, forced_frame=None):\n",
    "        if forced_frame is not None:\n",
    "            self.frame = forced_frame\n",
    "        elif self.frame < self.motion.timings[ 3]-1:\n",
    "            self.frame += 1\n",
    "\n",
    "        \n",
    "class Player:\n",
    "    def __init__(self, motion_list):\n",
    "        self.motion_list = motion_list\n",
    "        self.current_clip = None\n",
    "        self.next_clip = None\n",
    "        self.quaternions = np.array([1,0,0,0], dtype=np.float32)[np.newaxis,...].repeat(bone_count, axis=0)\n",
    "        self.positions = np.zeros([bone_count, 3], dtype=np.float32)\n",
    "        self.last_clip_position = np.zeros([3], dtype=np.float32)\n",
    "\n",
    "    def set_next_clip(self, clip_id):\n",
    "        if self.current_clip is None:\n",
    "            self.current_clip = ClipPlayer(self.motion_list[clip_id])\n",
    "        else:\n",
    "            self.next_clip = ClipPlayer(self.motion_list[clip_id])\n",
    "            self.next_clip.align_to_out(self.current_clip)\n",
    "        self.last_clip_position = self.positions[0, :]\n",
    "\n",
    "    def tick(self):\n",
    "        if self.current_clip is not None:\n",
    "            self.current_clip.tick()\n",
    "\n",
    "            self.quaternions = self.current_clip.quaternions[self.current_clip.frame]\n",
    "            self.positions = self.current_clip.positions[self.current_clip.frame]\n",
    "\n",
    "            if self.next_clip is not None:\n",
    "                if self.current_clip.frame >= self.next_clip.start_at_out_frame:\n",
    "                    tick_frame = self.next_clip.start_clip_frame + self.current_clip.frame - self.next_clip.start_at_out_frame\n",
    "                    self.next_clip.tick(tick_frame)\n",
    "\n",
    "                    t = float(self.current_clip.frame - self.next_clip.start_at_out_frame) / float(self.next_clip.blend_in_frame_count)\n",
    "                    self.quaternions = lab.utils.quat_slerp(self.current_clip.quaternions[self.current_clip.frame], self.next_clip.quaternions[self.next_clip.frame], t)\n",
    "                    self.positions = (1.0-t) * self.current_clip.positions[self.current_clip.frame] + (t) * self.next_clip.positions[self.next_clip.frame]\n",
    "                    \n",
    "                    if t >= .99 or self.next_clip.frame >= self.next_clip.motion.timings[ 1] or self.current_clip.frame >= self.current_clip.motion.timings[ 3] - 1 :\n",
    "                        self.current_clip = self.next_clip\n",
    "                        self.next_clip = None                 \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069f5d1-c9da-4f2c-9128-537905cebc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = Player(motion_clips)\n",
    "player.set_next_clip(0)\n",
    "\n",
    "def render(frame):\n",
    "\n",
    "    if player.next_clip is None:\n",
    "        if player.current_clip.motion.side == 0:\n",
    "            player.set_next_clip(randrange(LEFT_CLIP_COUNT, CLIP_COUNT))\n",
    "        else:\n",
    "            player.set_next_clip(randrange(0, LEFT_CLIP_COUNT))\n",
    "    \n",
    "    player.tick()\n",
    "    \n",
    "    q = player.quaternions\n",
    "    p = player.positions\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    a = lab.utils.quat_to_mat(player.current_clip.quaternions[player.current_clip.frame], player.current_clip.positions[player.current_clip.frame])\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a), np.array([1,0,0], dtype=np.float32))\n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    if player.next_clip is not None:\n",
    "        f = max(player.next_clip.frame, 0)\n",
    "        a = lab.utils.quat_to_mat(player.next_clip.quaternions[f], player.next_clip.positions[f])\n",
    "        viewer.draw_lines(character.world_skeleton_lines(a), np.array([0,1,0], dtype=np.float32))\n",
    "        viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be865947-b496-4913-96da-8914250927f2",
   "metadata": {},
   "source": [
    "## Transition Cost: Ensuring Physical Continuity Between Clips\n",
    "\n",
    "To generate smooth, physically plausible motion, we need to ensure that transitions between motion clips do not produce visible artifacts such as foot sliding, abrupt changes in joint positions, or unrealistic discontinuities in momentum.\n",
    "\n",
    "Setting the cost to be infinitaly high if it blends on the wrong foot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617842f-a818-4fa6-8c23-bd19be1d0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "progress_output = widgets.Output(layout={'border': '1px solid black'})\n",
    "display(progress_output)\n",
    "\n",
    "bone_filter = [bones.index(\"Hips\"), bones.index(\"Spine\"), bones.index(\"Spine1\"), bones.index(\"Spine2\"), bones.index(\"LeftUpLeg\"), bones.index(\"LeftLeg\"), bones.index(\"LeftFoot\"), bones.index(\"RightUpLeg\"), bones.index(\"RightLeg\"), bones.index(\"RightFoot\")]\n",
    "\n",
    "def pre_compute_transitions_costs(motion_clips, file_name=None):\n",
    "\n",
    "    count = len(motion_clips)\n",
    "    \n",
    "    physics_costs = np.ones([count, count]) * -1\n",
    "    delta_theta = np.zeros([count, count])\n",
    "    delta_x = np.zeros([count, count])\n",
    "    delta_z = np.zeros([count, count])\n",
    "\n",
    "    \n",
    "    for i in range(len(motion_clips)):\n",
    "        \n",
    "        progress_output.clear_output()\n",
    "        display(f\"clip {i} / {len(motion_clips)}\")\n",
    "\n",
    "        a = ClipPlayer(motion_clips[i])\n",
    "        a.quaternions[:, 0], a.positions[:, 0] = lab.utils.qp_mul(\n",
    "            lab.utils.qp_inv((a.quaternions[motion_clips[i].timings[1], 0][np.newaxis,...], a.positions[motion_clips[i].timings[1], 0][np.newaxis,...])),\n",
    "            (a.quaternions[:, 0], a.positions[:, 0])\n",
    "        )\n",
    "        aq, ap = lab.utils.quat_fk(a.quaternions, a.positions, parents)\n",
    "\n",
    "        for j in range(len(motion_clips)):\n",
    "            if motion_clips[i].side != motion_clips[j].side:\n",
    "                \n",
    "                b = ClipPlayer(motion_clips[j])\n",
    "                b.align_to_out(a)\n",
    "    \n",
    "                # compute cost\n",
    "                bq, bp = lab.utils.quat_fk(b.quaternions, b.positions, parents)\n",
    "                for k in range(b.blend_in_frame_count):\n",
    "                    v = ap[b.start_at_out_frame+k, bone_filter, ...] - bp[b.start_clip_frame+k, bone_filter, ...]\n",
    "                    physics_costs[i, j] += np.sum(np.sqrt(np.sum(v*v, axis=1)))\n",
    "                physics_costs[i, j] /= b.blend_in_frame_count\n",
    "                \n",
    "                # compute deltas\n",
    "                delta_x[i, j] = bp[motion_clips[j].timings[1], 0, 0]\n",
    "                delta_z[i, j] = bp[motion_clips[j].timings[1], 0, 2]\n",
    "                delta_theta[i, j] = np.atan2(\n",
    "                    2 * bq[motion_clips[j].timings[1], 0, 0] * bq[motion_clips[j].timings[1], 0, 2], \n",
    "                    1.0 - (2 * bq[motion_clips[j].timings[1], 0, 2] * bq[motion_clips[j].timings[1], 0, 2])\n",
    "                )\n",
    "\n",
    "    # normalize\n",
    "    physics_costs[:,:] /= physics_costs[physics_costs>=0].mean()\n",
    "\n",
    "    # discard the impossible transitions between feet\n",
    "    physics_costs[physics_costs<0] = 10000\n",
    "\n",
    "    if file_name is not None:\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump((physics_costs, delta_theta, delta_x, delta_z), f)\n",
    "\n",
    "    return physics_costs, delta_theta, delta_x, delta_z\n",
    "\n",
    "# with progress_output:\n",
    "#     physics_costs, delta_theta, delta_x, delta_z = pre_compute_transitions_costs(motion_clips, 'realtime_planning_animations_costs.dat')\n",
    "\n",
    "with open('realtime_planning_animations_costs.dat', 'rb') as f:\n",
    "    physics_costs, delta_theta, delta_x, delta_z = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8381d2b8-d3b8-4e9b-a375-f6f0b6c71f3f",
   "metadata": {},
   "source": [
    "## Optimal policy\n",
    "\n",
    "#### Value-Function Learning Pipeline\n",
    "\n",
    "1. **Initialize**\n",
    "   - Set $V^{(0)}(s) = 0$ for all $s$.\n",
    "   - Create empty training sets $\\mathcal{T}_a$ for every clip $a \\in \\mathcal{A}$.\n",
    "\n",
    "2. **Repeat until convergence**\n",
    "   1. **Sampling**\n",
    "      - For $k = 1 \\dots K$ trajectories:\n",
    "        - Pick random start state $s_0$.\n",
    "        - While not terminal:\n",
    "          - Choose action $a_t = \\operatorname{argmax}_{a'} \\bigl[R(s_t,a') + \\gamma V^{(i)}(f(s_t,a'))\\bigr]$.\n",
    "          - Store tuple $(s_t, v_t)$ with  \n",
    "            $v_t = R(s_t,a_t) + \\gamma V^{(i)}(f(s_t,a_t))$.\n",
    "          - Step to $s_{t+1}=f(s_t,a_t)$.\n",
    "\n",
    "   2. **Regression**\n",
    "      - For every clip $a$:\n",
    "        - Build **Extra-Tree** on $\\mathcal{T}_a$:\n",
    "          - I've used scipy implementation.\n",
    "\n",
    "   3. **Update**\n",
    "      - Construct new approximation $V^{(i+1)}$ from the forests.\n",
    "      - Re-evaluate all stored $(s,v)$ using $V^{(i+1)}$.\n",
    "\n",
    "   4. **Check convergence**\n",
    "      - Compute **Bellman residual**  \n",
    "        $\\displaystyle \\text{Res} = \\frac{1}{|\\mathcal{T}|}\\sum_{(s,v)\\in\\mathcal{T}} \\Bigl| v - \\max_{a'}\\bigl[R(s,a') + \\gamma V^{(i+1)}(f(s,a'))\\bigr]\\Bigr|^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7778c91-1943-4383-90a3-16ad55e6582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_compute_table = np.linspace(-np.pi, np.pi, 300)\n",
    "clip_arange = np.arange(CLIP_COUNT)\n",
    "\n",
    "def transition (clip_id, x, z, theta, next_clip_id):\n",
    "    x_prime = x + np.sin(theta) * delta_z[clip_id, next_clip_id] + np.cos(theta) * delta_x[clip_id, next_clip_id]\n",
    "    z_prime = z + np.cos(theta) * delta_z[clip_id, next_clip_id] - np.sin(theta) * delta_x[clip_id, next_clip_id]\n",
    "    theta_prime = theta + delta_theta[clip_id, next_clip_id]\n",
    "    theta_prime[theta_prime < -np.pi] += np.pi*2\n",
    "    theta_prime[theta_prime > np.pi] -= np.pi*2\n",
    "    return next_clip_id, x_prime, z_prime, theta_prime\n",
    "\n",
    "def transition_reward (clip_id, next_clip_id):\n",
    "    return -physics_costs[clip_id, next_clip_id] * 1.25\n",
    "\n",
    "def state_reward(clip_id, theta):\n",
    "    if clips_sources[clip_id] >= 25:\n",
    "        return -10\n",
    "    mc = motion_clips[clip_id]\n",
    "    theta_prime = theta + mc.delta_theta\n",
    "    if theta_prime < np.pi:\n",
    "        theta_prime += np.pi*2\n",
    "    if theta_prime > np.pi:\n",
    "        theta_prime -= np.pi*2\n",
    "    return -np.abs(theta)\n",
    "\n",
    "def get_value_function(value_functions, clip_id, theta_prime):\n",
    "    future_indices = np.searchsorted(pre_compute_table, theta_prime, side='right')\n",
    "    return value_functions[clip_id, future_indices]\n",
    "    \n",
    "def use_optimal_policy(value_functions, alpha, state_clip, state_theta):\n",
    "    _, x_prime, z_prime, theta_prime = transition(state_clip, 0, 0, state_theta, ...)\n",
    "\n",
    "    reward = transition_reward(state_clip, ...)\n",
    "    reward += alpha * get_value_function(value_functions, clip_arange, theta_prime)\n",
    "\n",
    "    picked = np.argmax(reward)\n",
    "\n",
    "    return picked, x_prime[picked], z_prime[picked], theta_prime[picked], reward[picked] + state_reward(state_clip, state_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d85874-b4c4-4200-8fac-df9986350055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_tree(model, X_new, y_new):\n",
    "    for tree_estimator in model.estimators_:\n",
    "        # Get the leaf indices for the new data\n",
    "        leaf_indices = tree_estimator.apply(X_new)\n",
    "        \n",
    "        # Get the tree object\n",
    "        tree = tree_estimator.tree_\n",
    "        \n",
    "        # Get the unique leaf nodes present in the new data for this tree\n",
    "        unique_leaves = np.unique(leaf_indices)\n",
    "        \n",
    "        for leaf_index in unique_leaves:\n",
    "            # Find the new data points that fall into this leaf\n",
    "            new_data_in_leaf_mask = leaf_indices == leaf_index\n",
    "            \n",
    "            # Calculate the new mean for this leaf\n",
    "            new_leaf_mean = np.mean(y_new[new_data_in_leaf_mask])\n",
    "            \n",
    "            # Update the value of the leaf node\n",
    "            # The value is a 1D array of size 1 for regression\n",
    "            tree.value[leaf_index, 0, 0] = new_leaf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4491c-12b2-43cc-8e8e-4debe7e26a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "display(progress_output)\n",
    "\n",
    "ALPHA = .95\n",
    "EPOCH = 5\n",
    "FREEZE_EPOCH = 4\n",
    "\n",
    "def train_optimal_policy():\n",
    "    progress_output.clear_output()\n",
    "    \n",
    "    value_functions = None\n",
    "    value_functions_precompute = np.zeros([CLIP_COUNT, pre_compute_table.shape[0]])\n",
    "\n",
    "    scores = np.zeros([EPOCH, 6])\n",
    "\n",
    "    count = np.zeros([CLIP_COUNT], dtype=np.uint32)\n",
    "    X = np.zeros([CLIP_COUNT, 100000])\n",
    "    y = np.zeros([CLIP_COUNT, 100000])\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        display(f\"epoch : [{epoch}]\")\n",
    "\n",
    "        # we stop adding new data once we are in the freeze tree state\n",
    "        if epoch < FREEZE_EPOCH:\n",
    "            #build a data set\n",
    "            display(f\"gather path data\")\n",
    "\n",
    "            for path in range(800):\n",
    "                clip = randrange(0, CLIP_COUNT)\n",
    "                theta = uniform(-np.pi, np.pi)\n",
    "        \n",
    "                for steps in range(10):\n",
    "                    next_clip, _, _, theta_prime, reward = use_optimal_policy(value_functions_precompute, ALPHA, clip, theta)\n",
    "                    \n",
    "                    X[clip, count[clip]] = theta\n",
    "                    y[clip, count[clip]] = reward\n",
    "                    count[clip] += 1\n",
    "    \n",
    "                    clip = next_clip\n",
    "                    theta = theta_prime\n",
    "\n",
    "       \n",
    "\n",
    "        #train the value functions\n",
    "        display(f\"train the value functions\")\n",
    "        # after 4 iteration we freeze the tree structures\n",
    "        if epoch < FREEZE_EPOCH:\n",
    "            value_functions = []\n",
    "            for i in range(CLIP_COUNT):\n",
    "                X_train, y_train = X[i, :count[i]], y[i, :count[i]]\n",
    "                model = ExtraTreesRegressor(n_estimators=50, random_state=None, n_jobs=-1)\n",
    "                model.fit(X_train.reshape(-1, 1), y_train)\n",
    "                value_functions.append(model)\n",
    "        else:\n",
    "            for i in range(CLIP_COUNT):\n",
    "                X_train, y_train = X[i, :count[i]], y[i, :count[i]]\n",
    "                refit_tree(value_functions[i], X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "        #precompute value functions\n",
    "        display(f\"precompute value functions\")\n",
    "        for i in range(CLIP_COUNT):\n",
    "            value_functions_precompute[i, :] = value_functions[i].predict(pre_compute_table[:, np.newaxis])\n",
    "\n",
    "        \n",
    "        #compute bellman residual\n",
    "        residuals = np.zeros([CLIP_COUNT * 100000])\n",
    "        c = 0\n",
    "        \n",
    "        # recompute the best value\n",
    "        display(f\"re evaluate Value functions\")\n",
    "        for i in range(CLIP_COUNT):\n",
    "            for j in range(count[i]):\n",
    "                _, _, _, _, reward = use_optimal_policy(value_functions_precompute, ALPHA, i, X[i,j])\n",
    "\n",
    "                residuals[c] = np.abs(get_value_function(value_functions_precompute, i, X[i,j]) - reward)\n",
    "                y[i, j] = reward\n",
    "                c+=1\n",
    "                \n",
    "        progress_output.clear_output()\n",
    "        display(f\"residuals; mean {residuals[:c].mean()} max {residuals[:c].max()}\")\n",
    "        scores[epoch, 0] = residuals[:c].min()\n",
    "        scores[epoch, 1] = residuals[:c].max()\n",
    "        scores[epoch, 2] = residuals[:c].mean()\n",
    "\n",
    "    with open('realtime_planning_orientation_value_functions.dat', 'wb') as f:\n",
    "        pickle.dump((value_functions_precompute, scores), f)\n",
    "\n",
    "    return value_functions_precompute, scores\n",
    "\n",
    "# with progress_output:\n",
    "#     value_functions_precompute, scores = train_optimal_policy()\n",
    "\n",
    "with open('realtime_planning_orientation_value_functions.dat', 'rb') as f:\n",
    "    value_functions_precompute, scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ae9e13-ddfd-408e-87d3-b73a96a3bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(EPOCH)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 4), sharex=True)\n",
    "\n",
    "# First subplot\n",
    "axs.plot(x, scores[:, 2], label='Mean', color='blue')\n",
    "axs.fill_between(x, scores[:, 0], scores[:, 1], color='lightblue', alpha=0.4, label='Min-Max Range')\n",
    "axs.set_title('Scores over Epoch (Mean and Range)')\n",
    "axs.set_ylabel('Value')\n",
    "axs.legend()\n",
    "axs.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52c603-c61b-4c0a-97e8-61f62f315973",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamepad = widgets.Controller(index=0)\n",
    "gamepad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac86c8-b2a7-4c03-8b94-511d655f3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = Player(motion_clips)\n",
    "player.set_next_clip(0)\n",
    "\n",
    "def render(frame):\n",
    "\n",
    "    controller_orient = np.array([1,0,0,0], dtype=np.float32)\n",
    "    posx = gamepad.axes[0].value \n",
    "    posz = -gamepad.axes[1].value \n",
    "    if np.abs(posx) > 0.001 or np.abs(posz) > 0.001:\n",
    "        angle = np.atan2(posz, posx)\n",
    "        controller_orient[0] = np.cos(angle/2)\n",
    "        controller_orient[2] = np.sin(angle/2)\n",
    "\n",
    "\n",
    "    if player.next_clip is None:\n",
    "        f = player.current_clip.motion.timings[1]\n",
    "\n",
    "        q = lab.utils.quat_mul(lab.utils.quat_inv(controller_orient), player.current_clip.quaternions[f, 0, :])\n",
    "        theta =  np.atan2(\n",
    "            2 * q[0] * q[2], \n",
    "            1.0 - (2 * q[2] * q[2])\n",
    "        )\n",
    "    \n",
    "        next_clip, _, _, _, _ = use_optimal_policy(value_functions_precompute, ALPHA, player.current_clip.motion._id, theta)\n",
    "        \n",
    "        player.set_next_clip(next_clip)\n",
    "\n",
    "    player.tick()\n",
    "    \n",
    "    q = player.quaternions\n",
    "    p = player.positions\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    d = lab.utils.quat_to_mat(controller_orient, p[0])\n",
    "    viewer.draw(direction, d)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d212a0-7c7c-4aa5-b4d1-c4bbc58dd9cf",
   "metadata": {},
   "source": [
    "### Reach goal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccde186-11de-464c-9408-1d63777bc95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of the stopping steps\n",
    "# we know the indices of the animations, we only take the last step of those as the stop it self\n",
    "def _last_step(source_id):\n",
    "    potential = np.argwhere(clips_sources == source_id)[:, 0]\n",
    "    return potential[clips_timings[potential, -1].argsort()[-1]]\n",
    "\n",
    "stops_indices = np.array( [_last_step(index) for index in [26,27,28,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46]], dtype=np.uint16)\n",
    "stops_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343a583-b371-4af9-b289-c66f073fb471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute local position to end on 0,0,0\n",
    "stops_positions = []\n",
    "for id in stops_indices:\n",
    "    player = Player(motion_clips)\n",
    "    player.set_next_clip(id)\n",
    "    player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0] = lab.utils.qp_mul(\n",
    "        lab.utils.qp_inv((player.current_clip.quaternions[player.current_clip.motion.timings[3]-1, 0][np.newaxis,...], player.current_clip.positions[player.current_clip.motion.timings[3]-1, 0][np.newaxis,...])),\n",
    "        (player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0])\n",
    "    )\n",
    "    pos =  - player.current_clip.positions[player.current_clip.motion.timings[1], 0]\n",
    "    pos = lab.utils.quat_mul_vec(lab.utils.quat_inv(player.current_clip.quaternions[player.current_clip.motion.timings[1], 0]), pos)\n",
    "    stops_positions.append(pos)\n",
    "stops_positions = np.array(stops_positions, dtype=np.float32)\n",
    "stops_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabec356-ebf5-4da9-8194-8a7845c83539",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_compute_table_x = np.linspace(-1000, 1000, 1001)\n",
    "pre_compute_table_z = np.linspace(-1000, 1000, 1001)\n",
    "\n",
    "clip_arange = np.arange(CLIP_COUNT)\n",
    "mask = np.ones(clip_arange.shape, bool)\n",
    "mask[np.argwhere(clips_sources == 25)[:, 0]] = False\n",
    "mask[np.argwhere(clips_sources == 29)[:, 0]] = False\n",
    "mask[np.argwhere(clips_sources == 30)[:, 0]] = False\n",
    "clip_arange = clip_arange[mask]\n",
    "\n",
    "clip_arange_no_stop = np.arange(CLIP_COUNT)\n",
    "mask = np.ones(clip_arange_no_stop.shape, bool)\n",
    "mask[stops_indices] = False\n",
    "mask[np.argwhere(clips_sources == 25)[:, 0]] = False\n",
    "mask[np.argwhere(clips_sources == 29)[:, 0]] = False\n",
    "mask[np.argwhere(clips_sources == 30)[:, 0]] = False\n",
    "clip_arange_no_stop = clip_arange_no_stop[mask]\n",
    "\n",
    "\n",
    "def transition (clip_id, x, z, next_clip_id):\n",
    "    x_prime = x - delta_x[clip_id, next_clip_id]\n",
    "    z_prime = z - delta_z[clip_id, next_clip_id]\n",
    "    theta_prime = delta_theta[clip_id, next_clip_id]\n",
    "    \n",
    "    x_rot = np.cos(theta_prime) * x_prime - np.sin(theta_prime) * z_prime \n",
    "    z_rot = np.cos(theta_prime) * z_prime + np.sin(theta_prime) * x_prime\n",
    "    \n",
    "    return next_clip_id, x_rot, z_rot\n",
    "\n",
    "def transition_inv (previous_clip_id, clip_id, x, z):\n",
    "    theta_prime = -delta_theta[previous_clip_id, clip_id]\n",
    "    \n",
    "    x_rot = np.cos(theta_prime) * x - np.sin(theta_prime) * z \n",
    "    z_rot = np.cos(theta_prime) * z + np.sin(theta_prime) * x\n",
    "    \n",
    "    return previous_clip_id, x_rot + delta_x[previous_clip_id, clip_id], z_rot + delta_z[previous_clip_id, clip_id]\n",
    "\n",
    "def transition_reward (clip_id, next_clip_id):\n",
    "    return -physics_costs[clip_id, next_clip_id] * 2.\n",
    "\n",
    "def state_reward(clip_id, x, z):\n",
    "    if clip_id in stops_indices:\n",
    "        index = np.argwhere(stops_indices == clip_id)[0][0]\n",
    "        px = x - stops_positions[index, 0]\n",
    "        pz = z - stops_positions[index, 2]\n",
    "\n",
    "        dist = np.sqrt(np.sum(px*px + pz*pz))\n",
    "        if dist < 50:\n",
    "            return 1\n",
    "        else:\n",
    "            return -100\n",
    "\n",
    "    dist = np.sqrt(np.sum(x*x + z*z))\n",
    "    if dist > 300:\n",
    "        return (300-dist) * 0.005\n",
    "    return 0\n",
    "\n",
    "def get_value_function(value_functions, clip_id, x_prime, z_prime):\n",
    "    x_indices = np.clip(np.searchsorted(pre_compute_table_x, x_prime)-1, 0, pre_compute_table_x.shape[0]-1)\n",
    "    z_indices = np.clip(np.searchsorted(pre_compute_table_z, z_prime)-1, 0, pre_compute_table_z.shape[0]-1)\n",
    "    return value_functions_precompute[clip_id, z_indices, x_indices]\n",
    "\n",
    "def use_optimal_policy(value_functions, alpha, state_clip, x, z, no_stop=False):\n",
    "    indices = clip_arange\n",
    "    if no_stop:\n",
    "        indices = clip_arange_no_stop\n",
    "        \n",
    "    _, x_prime, z_prime = transition(state_clip, x, z, indices)\n",
    "\n",
    "    reward = transition_reward(state_clip, indices)\n",
    "    reward += alpha * get_value_function(value_functions, indices, x_prime, z_prime)\n",
    "\n",
    "    picked =np.argmax(reward)\n",
    "\n",
    "    # now let's forbid taking a transition toward a stop if it fails\n",
    "    if no_stop==False and state_reward(clip_arange[picked], x_prime[picked], z_prime[picked]) < -99:\n",
    "        return use_optimal_policy(value_functions, alpha, state_clip, x, z, True)\n",
    "        \n",
    "    return indices[picked], x_prime[picked], z_prime[picked], reward[picked] + state_reward(state_clip, x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbfb74-3c8d-47c8-8ed2-420657456e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollback_trajectories(state_clip, state_x, state_z, alpha, spread=1, rollback_len=10):\n",
    "    \n",
    "    trajectory = []\n",
    "    trajectory.append((\n",
    "        state_clip, state_x, state_z, state_reward(state_clip, state_x, state_z)\n",
    "    ))\n",
    "    \n",
    "    def _roll(state_clip, state_x, state_z):\n",
    "        \n",
    "        previous_clip = physics_costs[:, state_clip].argsort()[randrange(0, spread)]\n",
    "        _, xp, zp = transition_inv(previous_clip, state_clip, state_x, state_z )\n",
    "\n",
    "        trajectory.append((\n",
    "            previous_clip, xp, zp, trajectory[-1][3] * alpha - physics_costs[previous_clip, state_clip] * .1\n",
    "        ))\n",
    "        \n",
    "        if len(trajectory) < rollback_len:\n",
    "            _roll(previous_clip, xp, zp)\n",
    "\n",
    "    _roll(state_clip, state_x, state_z)\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6bc10-270d-4695-8c3d-a26aad507f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = []\n",
    "def _create_one_player ():\n",
    "    player = Player(motion_clips)\n",
    "    stop_id = randrange(0, len(stops_indices))\n",
    "    \n",
    "    player.trajectory = list( reversed (rollback_trajectories(stops_indices[stop_id], stops_positions[stop_id,0], stops_positions[stop_id,2], .95, spread=5, rollback_len=8)) )\n",
    "    player.set_next_clip(player.trajectory[0][0])\n",
    "    player.current_clip.frame = player.current_clip.motion.timings[1]\n",
    "    player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0] = lab.utils.qp_mul(\n",
    "        lab.utils.qp_inv((player.current_clip.quaternions[player.current_clip.motion.timings[1], 0][np.newaxis,...], player.current_clip.positions[player.current_clip.motion.timings[1], 0][np.newaxis,...])),\n",
    "        (player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0])\n",
    "    )\n",
    "    player.trajectory_id = 0\n",
    "    player.current_clip.positions[:, 0] -= [player.trajectory[0][1], 0, player.trajectory[0][2]]\n",
    "    return player\n",
    "    \n",
    "for i in range(20):\n",
    "    players.append(_create_one_player())\n",
    "\n",
    "def render(frame):\n",
    "\n",
    "    for player in players:\n",
    "        if player.next_clip is None:\n",
    "            player.trajectory_id += 1\n",
    "            if player.trajectory_id < len(player.trajectory):\n",
    "            \n",
    "                player.set_next_clip(player.trajectory[player.trajectory_id][0])\n",
    "    \n",
    "        player.tick()\n",
    "    \n",
    "    q = player.quaternions\n",
    "    p = player.positions\n",
    "\n",
    "    # pos =  - p[0]\n",
    "    # pos = lab.utils.quat_mul_vec(lab.utils.quat_inv(q[0]), pos)\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    for player in players:\n",
    "        q = player.quaternions\n",
    "        p = player.positions\n",
    "        a = lab.utils.quat_to_mat(q, p)\n",
    "        viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    for player in players:\n",
    "        q = player.quaternions\n",
    "        p = player.positions\n",
    "        a = lab.utils.quat_to_mat(q, p)\n",
    "        viewer.draw(character, a)\n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "\n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc4f9b-d0b9-4713-a261-b61dcdf0b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_states = np.zeros([1000000000, 4], dtype=np.float32)\n",
    "all_valid_states_count = 0\n",
    "\n",
    "def _rollback_all(state_clip, state_x, state_z, action_id, recursion_counter):\n",
    "    global all_valid_states_count\n",
    "    previous_clip = physics_costs[:, state_clip].argsort()[action_id]\n",
    "    clip_prime, x_prime, z_prime = transition_inv(previous_clip, state_clip, state_x, state_z )\n",
    "    if clip_prime not in stops_indices:\n",
    "        all_valid_states[all_valid_states_count, :] = ((clip_prime, x_prime, z_prime, recursion_counter))\n",
    "        all_valid_states_count += 1\n",
    "        recursion_counter += 1\n",
    "        if recursion_counter < 4:\n",
    "            for i in range(5):\n",
    "                _rollback_all(clip_prime, x_prime, z_prime, i, recursion_counter)\n",
    "\n",
    "for state_clip in stops_indices:\n",
    "    stop_id = np.argwhere(stops_indices == state_clip)[0][0]\n",
    "\n",
    "    for _ in range(100):\n",
    "        x = uniform(-20, 20)\n",
    "        z = uniform(-20, 20)\n",
    "    \n",
    "        for i in range(5):\n",
    "            all_valid_states[all_valid_states_count, :] = ((state_clip, stops_positions[stop_id,0] + x, stops_positions[stop_id,2] + z, 0))\n",
    "            all_valid_states_count += 1\n",
    "            _rollback_all(state_clip,stops_positions[stop_id,0] + x, stops_positions[stop_id,2] + z, i, 1)\n",
    "\n",
    "all_valid_states = all_valid_states[:all_valid_states_count, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1a3e8-1391-483f-9747-d58b1847745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sc, = ax.plot([], [], 'o')  # placeholder line object\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('z')\n",
    "ax.set_title('Clip')\n",
    "ax.set_xlim(-500, 500)\n",
    "ax.set_ylim(-500, 500)\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True)\n",
    "\n",
    "def plot_clip(clip_id):\n",
    "    selected = all_valid_states[all_valid_states[:, 0] == clip_id]\n",
    "    x = selected[:, 1]\n",
    "    z = selected[:, 2]\n",
    "    sc.set_data(x, z)\n",
    "    ax.relim()\n",
    "    ax.autoscale_view()\n",
    "    ax.set_title(f'Clip ID: {clip_id}')\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Interactive slider\n",
    "interact(plot_clip, clip_id=widgets.IntSlider(min=0, max=CLIP_COUNT-1, step=1, value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0f7b5-940a-405a-a70d-09c98e4179ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from multiprocessing import Pool\n",
    "import importlib\n",
    "import RealTimePlanning_MultiProcess_Func as mpf\n",
    "importlib.reload(mpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc184bc2-eff8-4471-9693-24b505a70673",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_functions_precompute = np.zeros([CLIP_COUNT, pre_compute_table_x.shape[0], pre_compute_table_z.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08e782-8d58-49b5-b9d9-37ba4fad1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "display(progress_output)\n",
    "\n",
    "ALPHA = .99\n",
    "EPOCH = 50\n",
    "RESTART_EPOCH = 10\n",
    "LEARN_RATE = 0.1\n",
    "\n",
    "PRE_COMPUTE_TABLE_INDICES = np.stack(np.meshgrid(pre_compute_table_x, pre_compute_table_z), axis=2).reshape(-1, 2)\n",
    "\n",
    "def _generate_data(count, X, y):\n",
    "    # force all the known path\n",
    "    for s in all_valid_states[::50]:\n",
    "        clip, x, z, rec = int(s[0]), s[1], s[2], s[3]\n",
    "        X[clip, count[clip], 0] = x\n",
    "        X[clip, count[clip], 1] = z\n",
    "        y[clip, count[clip]] = 1.0 * (ALPHA ** rec)\n",
    "        count[clip] += 1\n",
    "\n",
    "    # fail\n",
    "    for clip in range(CLIP_COUNT):\n",
    "\n",
    "        selected = all_valid_states[all_valid_states[:, 0] == clip]\n",
    "        if selected.shape[0] > 0:\n",
    "        \n",
    "            tree = cKDTree(selected[:, 1:3])\n",
    "\n",
    "            sp = np.linspace(-500, 500, 201)\n",
    "            grid_positions = np.stack(np.meshgrid(sp, sp), axis=2).reshape(-1, 2)\n",
    "            \n",
    "            # Query nearest neighbor distances\n",
    "            distances, _ = tree.query(grid_positions, k=1)\n",
    "    \n",
    "            for i in range(grid_positions.shape[0]):\n",
    "                if distances[i] > 4 and distances[i] < 20 :\n",
    "                    X[clip, count[clip], 0] = grid_positions[i, 0]\n",
    "                    X[clip, count[clip], 1] = grid_positions[i, 1]\n",
    "                    y[clip, count[clip]] = 0\n",
    "                    count[clip] += 1\n",
    "        \n",
    "\n",
    "def train_optimal_policy():\n",
    "    progress_output.clear_output()\n",
    "\n",
    "    scores = np.zeros([EPOCH, 4])\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            display(f\"epoch : [{epoch}]\")\n",
    "    \n",
    "            if epoch % RESTART_EPOCH == 0:\n",
    "                display(f\"bootstrap\")\n",
    "                count = np.zeros([CLIP_COUNT], dtype=np.uint32)\n",
    "                X = np.zeros([CLIP_COUNT, 100000, 2])\n",
    "                y = np.zeros([CLIP_COUNT, 100000])\n",
    "                _generate_data(count, X, y)\n",
    "                \n",
    "            #build a data set\n",
    "            display(f\"gather path data\")\n",
    "            reach_reward = 0\n",
    "\n",
    "            for _ in range(20):\n",
    "                for clip in range(CLIP_COUNT):\n",
    "                    x = uniform(-500, 500)\n",
    "                    z = uniform(-500, 500)\n",
    "            \n",
    "                    for steps in range(10):\n",
    "                        if state_reward(clip, x, z) >= 1:\n",
    "                            reach_reward += 1\n",
    "                            break\n",
    "                        \n",
    "                        c, x_prime, z_prime, reward = use_optimal_policy(value_functions_precompute, ALPHA, clip, x, z)\n",
    "                        \n",
    "                        X[clip, count[clip], 0] = x\n",
    "                        X[clip, count[clip], 1] = z\n",
    "                        y[clip, count[clip]] = reward\n",
    "                        count[clip] += 1\n",
    "        \n",
    "                        clip = c\n",
    "                        x = x_prime\n",
    "                        z = z_prime\n",
    "    \n",
    "            # found \n",
    "            display(f\"found {reach_reward} succesful paths\")\n",
    "                \n",
    "                    \n",
    "            #train the value functions\n",
    "            display(f\"train the value functions\")\n",
    "            args = [(X[i, :count[i]], y[i, :count[i]], PRE_COMPUTE_TABLE_INDICES, pre_compute_table_x.shape[0]) for i in range(CLIP_COUNT)]\n",
    "            results = pool.starmap(mpf.reach_train_value_function, args)\n",
    "            value_functions_precompute[:, :, :] = np.stack(results)\n",
    "            \n",
    "            #compute bellman residual\n",
    "            residuals = np.zeros([CLIP_COUNT * 10000])\n",
    "            c = 0\n",
    "    \n",
    "            display(f\"re evaluate Value functions\")\n",
    "            for i in range(CLIP_COUNT):\n",
    "                for j in range(count[i]):\n",
    "                    _, _, _, reward = use_optimal_policy(value_functions_precompute, ALPHA, i, X[i,j, 0], X[i,j, 1])\n",
    "    \n",
    "                    residuals[c] = np.abs(y[i, j] - reward)\n",
    "                    \n",
    "                    y[i, j] += LEARN_RATE * (reward - y[i, j])\n",
    "                    c+=1\n",
    "    \n",
    "            progress_output.clear_output()\n",
    "            display(f\"residuals; mean {residuals[:c].mean()} max {residuals[:c].max()} total states count {np.sum(count)}\")\n",
    "            scores[epoch, 0] = residuals[:c].min()\n",
    "            scores[epoch, 1] = residuals[:c].max()\n",
    "            scores[epoch, 2] = residuals[:c].mean()\n",
    "            scores[epoch, 3] = reach_reward\n",
    "    \n",
    "    with open('realtime_planning_reach_position_value_functions.dat', 'wb') as f:\n",
    "        pickle.dump((value_functions_precompute, scores), f)\n",
    "\n",
    "    return value_functions_precompute, scores\n",
    "\n",
    "# with progress_output:\n",
    "#     value_functions_precompute, scores = train_optimal_policy()\n",
    "\n",
    "with open('realtime_planning_reach_position_value_functions.dat', 'rb') as f:\n",
    "    value_functions_precompute, scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683d85b-4794-440f-bce4-1e57bc3b03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(EPOCH)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# First subplot\n",
    "axs[0].plot(x, scores[:, 2], label='Mean', color='blue')\n",
    "axs[0].fill_between(x, scores[:, 0], scores[:, 1], color='lightblue', alpha=0.4, label='Min-Max Range')\n",
    "axs[0].set_title('Scores over Epoch (Mean and Range)')\n",
    "axs[0].set_ylabel('Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second subplot\n",
    "axs[1].plot(x, scores[:, 3], label='Found', color='blue')\n",
    "axs[1].set_title('Scores over Epoch (Found)')\n",
    "axs[1].set_xlabel('Index')\n",
    "axs[1].set_ylabel('Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a50c81-1afd-413b-9503-7069046973eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "plt.clf()\n",
    "X, Y = np.meshgrid(pre_compute_table_x,pre_compute_table_z)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, value_functions_precompute[16], cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Z Axis')\n",
    "ax.set_zlabel('Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b4c1a-3669-4b89-a4db-1c4bb4f50298",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = Player(motion_clips)\n",
    "player.set_next_clip(119)\n",
    "player.target = np.array([-200, 0, 500], dtype=np.float32)\n",
    "player.wait_counter = 0\n",
    "\n",
    "def render(frame):\n",
    "\n",
    "    if player.next_clip is None and player.current_clip.motion.timings[1] <= player.current_clip.frame:\n",
    "        if player.current_clip.motion._id not in stops_indices:\n",
    "\n",
    "            pos = player.target - player.positions[0, :]\n",
    "            pos = lab.utils.quat_mul_vec(lab.utils.quat_inv(player.quaternions[0, :]), pos)\n",
    "\n",
    "            # if we reach the reward we can transition to a stop\n",
    "            if state_reward(player.current_clip.motion._id, pos[0], pos[2]) > 1:\n",
    "                index = physics_costs[player.current_clip.motion._id, stops_indices].argmin()\n",
    "                player.set_next_clip(stops_indices[index])\n",
    "\n",
    "            else:\n",
    "                next_clip, x_prime, z_prime, reward = use_optimal_policy(value_functions_precompute, ALPHA, player.current_clip.motion._id, pos[0], pos[2])\n",
    "                display((pos, next_clip, x_prime, z_prime, reward))\n",
    "            \n",
    "                player.set_next_clip(next_clip)\n",
    "        else:\n",
    "            player.wait_counter += 1\n",
    "            if player.wait_counter > 15:\n",
    "                player.target = np.array([uniform(-400, 400), 0, uniform(-400, 400)], dtype=np.float32)\n",
    "                player.set_next_clip(119)\n",
    "                player.wait_counter = 0\n",
    "\n",
    "    player.tick()\n",
    "    \n",
    "    q = player.quaternions\n",
    "    p = player.positions\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    d = lab.utils.quat_to_mat(np.array([1,0,0,0], dtype=np.float32), player.target)\n",
    "    viewer.draw(target, d)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5acb85d-32ef-4d4f-b4f3-aa5835468a46",
   "metadata": {},
   "source": [
    "---\n",
    "## Motion Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45ffd1d-1ed7-49cb-ab26-3b2ddd36a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionGroup:\n",
    "    def __init__(self, indices, weights, id):\n",
    "        self.indices = np.array(indices, dtype=np.uint32)\n",
    "        self.weights = np.array(weights, dtype=np.float32)\n",
    "        self.weights/= np.sum(self.weights)\n",
    "        self.timings = np.sum(clips_timings[self.indices, :4] * self.weights[:, np.newaxis], axis=0).astype(np.uint32)\n",
    "        self.side = clips_sides[indices[0]]\n",
    "        self.quats = np.array([1,0,0,0], dtype=np.float32)[np.newaxis,...].repeat(MAX_STEP_LEN * bone_count, axis=0).reshape(MAX_STEP_LEN, bone_count, 4)\n",
    "        self.pos = np.array([0,0,0], dtype=np.float32).repeat(MAX_STEP_LEN * bone_count).reshape(MAX_STEP_LEN, bone_count, 3)\n",
    "        self.constraints_q = np.zeros([2, 4], dtype=np.float32)\n",
    "        self.constraints_p = np.zeros([2, 3], dtype=np.float32)\n",
    "        self._id = id\n",
    "        \n",
    "\n",
    "        self._interpolated_timings = np.zeros([self.indices.shape[0], self.timings[3]+1])\n",
    "        for i in range(self.indices.shape[0]):\n",
    "            self._interpolated_timings[i, :] = np.linspace(0, clips_timings[self.indices[i], 3], self.timings[3]+1)\n",
    "\n",
    "        def _accumulate(accum, q):\n",
    "            q_inv = -q\n",
    "            \n",
    "            replace_mask = np.sum(accum * q, axis=-1) < np.sum(accum * q_inv, axis=-1)\n",
    "            replace_mask = replace_mask[..., np.newaxis]\n",
    "            accum += replace_mask * q_inv + (1.0 - replace_mask) * q\n",
    "        \n",
    "        for frame in range(self.timings[3]+1):\n",
    "            self.quats[frame, ...] = 0\n",
    "            for i in range(self.indices.shape[0]):\n",
    "                source_frame = np.floor(self._interpolated_timings[i, frame]).astype(np.uint32)\n",
    "                source_interpolation = self._interpolated_timings[i, frame] - source_frame\n",
    "                \n",
    "\n",
    "                _accumulate(self.quats[frame, ...], clips_q[self.indices[i], source_frame, :, :] * (1.0-source_interpolation) * self.weights[i])\n",
    "                _accumulate(self.quats[frame, ...], clips_q[self.indices[i], source_frame+1, :, :] * (source_interpolation) * self.weights[i])\n",
    "\n",
    "                self.pos[frame, ...] += clips_p[self.indices[i], source_frame, :, :] * (1.0-source_interpolation) * self.weights[i]\n",
    "                self.pos[frame, ...] += clips_p[self.indices[i], source_frame+1, :, :] * (source_interpolation) * self.weights[i]\n",
    "        self.quats[...] = lab.utils.quat_normalize(self.quats)\n",
    "\n",
    "        _, gpos = lab.utils.quat_fk(self.quats, self.pos, animations[0].parents)\n",
    "        if self.side == 0:\n",
    "            self.constraints_q[0, :], self.constraints_p[0, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[0],\n",
    "                foottag_indices[0],\n",
    "                foottag_indices[1]\n",
    "            )\n",
    "            self.constraints_q[1, :], self.constraints_p[1, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[2],\n",
    "                foottag_indices[2],\n",
    "                foottag_indices[3]\n",
    "            )\n",
    "        else:\n",
    "            self.constraints_q[0, :], self.constraints_p[0, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[0],\n",
    "                foottag_indices[2],\n",
    "                foottag_indices[3]\n",
    "            )\n",
    "            self.constraints_q[1, :], self.constraints_p[1, :] = compute_constraint_qp(\n",
    "                gpos, \n",
    "                self.timings[2],\n",
    "                foottag_indices[0],\n",
    "                foottag_indices[1]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc0fab-0cf4-49e9-a8e5-2aea5a59d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, w1=1.0, w2=0.0, w3=0.0):\n",
    "\n",
    "    motion = MotionGroup([1,8,14], [w1, w2, w3], 0)\n",
    "    q = motion.quats[frame]\n",
    "    p = motion.pos[frame]\n",
    "    \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    contacts_matrices = np.eye(4, dtype=np.float32)[np.newaxis,...].repeat(2, axis=0)\n",
    "    contacts_matrices = lab.utils.quat_to_mat( motion.constraints_q,  motion.constraints_p )\n",
    "\n",
    "    viewer.draw(target, contacts_matrices)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.draw_axis(contacts_matrices, 20)\n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254dec8-637a-4205-842c-dab64c45d72c",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e796aa-64a5-4f49-82a2-c9297b8aa453",
   "metadata": {},
   "source": [
    "* 0 -> 9 - walks curved\n",
    "* 10 -> 23 - turns\n",
    "* 24 - walk straight  \n",
    "* 25 - start  \n",
    "* 26 - stop  \n",
    "* 27 - stop  \n",
    "* 28 - stop  \n",
    "* 29 - walk real slow  \n",
    "* 30 - walk slow  \n",
    "* 31 -> 46 -  stop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfa90c-7661-4430-9afa-cbbd4067cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_clip = np.arange(CLIP_COUNT)\n",
    "# mask = np.zeros(sorted_clip.shape, bool)\n",
    "# mask[np.argwhere(clips_sources < 47)[:, 0]] = True\n",
    "# mask[np.argwhere(clips_sources < 31)[:, 0]] = False\n",
    "# mask[np.argwhere(clips_sides == 0)[:, 0]] = False\n",
    "# sorted_clip = sorted_clip[mask]\n",
    "# sorted_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e499816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_clip = np.arange(CLIP_COUNT)\n",
    "# mask = np.zeros(sorted_clip.shape, bool)\n",
    "# mask[np.argwhere(clips_sources > 30 )[:, 0]] = True\n",
    "# mask[np.argwhere(clips_sources == 24)[:, 0]] = True\n",
    "# mask[stops_indices] = False\n",
    "# mask[np.argwhere(clips_sides == 0)[:, 0]] = False\n",
    "# sorted_clip = sorted_clip[mask]\n",
    "# sorted_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41281fb5-e5e0-4a2c-8b85-6e323c3106e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_is = np.arange(CLIP_COUNT)\n",
    "# angles = np.atan2(\n",
    "#     2 * clips_q[clip_is, clips_timings[:, 1], 0, 0] * clips_q[clip_is, clips_timings[:, 1], 0, 2], \n",
    "#     1.0 - (2 * clips_q[clip_is, clips_timings[:, 1], 0, 2] * clips_q[clip_is, clips_timings[:, 1], 0, 2])\n",
    "# )*180.0 / np.pi\n",
    "# distances = np.sqrt(clips_p[clip_is, clips_timings[:, 1], 0, 0]**2 + clips_p[clip_is, clips_timings[:, 1], 0, 2]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_indices_by_distance(indices, values, max_distance=2):\n",
    "#     groups = []\n",
    "#     current_group = [indices[0]]\n",
    "#     current_sign = np.sign(values[0])\n",
    "#     for i in range(1, len(indices)):\n",
    "#         sign = np.sign(values[i])\n",
    "#         if sign != current_sign or abs(values[i] - values[i-1]) >= max_distance:\n",
    "#             if 2 <= len(current_group) <= 3:\n",
    "#                 groups.append(current_group.copy())\n",
    "#             current_group = [indices[i-1], indices[i]]\n",
    "#             current_sign = sign\n",
    "#         else:\n",
    "#             current_group.append(indices[i])\n",
    "#             if len(current_group) == 3:\n",
    "#                 groups.append(current_group.copy())\n",
    "#                 current_group = [indices[i]]\n",
    "#                 current_sign = sign\n",
    "#     if 2 <= len(current_group) <= 3:\n",
    "#         groups.append(current_group)\n",
    "#     return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67574560-3d98-433f-a28f-1ff34ca1aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = list(zip(sorted_clip[np.argsort(angles[sorted_clip])], sorted(angles[sorted_clip])))\n",
    "# indices, values = zip(*pairs)\n",
    "# grouped_indices = group_indices_by_distance(list(indices), list(values), max_distance=2)\n",
    "# print([[int(i) for i in group] for group in grouped_indices])\n",
    "\n",
    "# list(zip ( sorted_clip[np.argsort(angles[sorted_clip])], sorted(angles[sorted_clip]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = list(zip(sorted_clip[np.argsort(distances[sorted_clip])], sorted(distances[sorted_clip])))\n",
    "# indices, values = zip(*pairs)\n",
    "# grouped_indices = group_indices_by_distance(list(indices), list(values), max_distance=5)\n",
    "# print([[int(i) for i in group] for group in grouped_indices])\n",
    "\n",
    "# list(zip ( sorted_clip[np.argsort(distances[sorted_clip])], sorted(distances[sorted_clip]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c90d27-311b-482e-8b9c-867bcd169edd",
   "metadata": {},
   "source": [
    "### Build the motion groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19aa05-868e-4013-a626-411f625f548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motion_groups_indices = [\n",
    "#     # rotate\n",
    "#     [80, 79], [79, 74], [74,73,85], [85,87], [87,81], [81,86], [84, 88], [88,83], [83,82], [82, 78], [78,77], [77, 75, 76],\n",
    "#     [0,1,7], [7,6,8], [8,14], [14,9,15], [15,13], [10,12,11], [11,17,16], [16,4,5], [5,3], [3,2],\n",
    "#     # turn\n",
    "#     [112, 114], [114, 108, 110], [110, 106], [106, 115], [115, 104, 111], [111, 105, 113], [113, 109, 103], [103, 107], [107, 91, 95], [95, 99, 93], [93, 101, 97], [97, 89], [98, 102, 96], [96, 92], [92, 100], [100, 90, 94],\n",
    "#     [45, 47], [47, 41], [41, 43], [43, 39], [39, 37], [37, 35], [46, 38], [38, 40, 42], [42, 18], [18, 34, 44], [44, 28], [28, 36, 21], [21, 30, 32], [32, 26], [26, 33, 24], [24, 22], [22, 31], [31, 19], [19, 29], [29, 25], [25, 27, 20], [20, 23],\n",
    "\n",
    "#     # walk\n",
    "#     [57, 64], [64, 59, 62], [62, 63, 49], [49, 58, 48], [48, 61, 60],\n",
    "#     [117, 141, 118], [118, 116, 134], [134, 136, 139], [139, 135, 140], [140, 137], [137, 138],\n",
    "\n",
    "#     #stop indices\n",
    "#     [131, 121, 132], [132, 128, 127], [127, 130, 129], [129, 133, 126],\n",
    "#     [71, 67, 70], [70, 69, 66], [66, 52], [52, 72, 68], [68, 51, 65]\n",
    "# ]\n",
    "\n",
    "motion_groups_indices = [\n",
    "    # rotate\n",
    "    [80, 79], [74,73,85], [85,87], [87,81], [81,86], [84, 88], [88,83], [83,82], [82, 78], [78,77], [77, 75, 76],\n",
    "    [0,1], [7,6], [6,8], [8,14], [14,9,15], [15,13], [10,12,11], [11,17,16], [16,4,5], [5,3], [3,2],\n",
    "    # turn\n",
    "    [112, 114], [114, 108, 110], [110, 106], [115, 104, 111], [111, 105, 113], [113, 109, 103], [103, 107], [107, 91, 95], [95, 99, 93], [93, 101, 97], [97, 89], [98, 102, 96], [96, 92], [100, 94], [90, 94],\n",
    "    [45, 47], [47, 41], [41, 43], [43, 39], [39, 37], [37, 35], [46, 38], [38, 40, 42], [42, 18], [18, 34, 44], [44, 28], [28, 36, 21], [21, 30, 32], [32, 26], [26, 33, 24], [24, 22], [22, 31], [29, 25], [25, 27, 20], [20, 23],\n",
    "\n",
    "    # walk\n",
    "    [57, 64], [64, 59, 62], [62, 63, 49], [49, 58, 48], [48, 61, 60],\n",
    "    [117, 141, 118], [118, 116, 134], [134, 136, 139], [139, 135, 140], [140, 137], [137, 138],\n",
    "\n",
    "    #stop indices\n",
    "    [131, 121, 132], [132, 128, 127], [127, 130, 129], [129, 133, 126],\n",
    "    [71, 67, 70], [70, 69, 66], [66, 52], [52, 72, 68], [68, 51, 65]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8110795-bb10-472f-9829-8687d8922493",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = np.ones([11, 1], dtype=np.float32)\n",
    "\n",
    "weights_2 = np.zeros([11, 2], dtype=np.float32)\n",
    "weights_2[:, 0] = 1. - np.linspace(0, 1, 12, dtype=np.float32)[1:]\n",
    "weights_2[:, 1] = np.linspace(0, 1, 12, dtype=np.float32)[1:]\n",
    "\n",
    "weights_3 = np.zeros([11, 3], dtype=np.float32)\n",
    "weights_3[:, 0] = 1.0 - np.linspace(0, 1, 12, dtype=np.float32)[1:]\n",
    "weights_3[:6, 1] = np.linspace(0, 1, 7, dtype=np.float32)[1:]\n",
    "weights_3[5:, 1] = 1.0- np.linspace(0, 1, 6, dtype=np.float32)\n",
    "weights_3[:, 2] = np.linspace(0, 1, 12, dtype=np.float32)[1:]\n",
    "weights_3 = weights_3 / np.sum(weights_3, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d50df-a772-47cf-8505-4a3f9a65cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_groups = []\n",
    "for indices in motion_groups_indices:\n",
    "    weights = weights_1\n",
    "    if len(indices) == 2:\n",
    "        weights = weights_2\n",
    "    if len(indices) == 3:\n",
    "        weights = weights_3\n",
    "\n",
    "    for w in weights:\n",
    "        mg = MotionGroup(indices, w, len(motion_groups))\n",
    "        motion_groups.append(mg)\n",
    "GROUP_COUNT = len(motion_groups)\n",
    "GROUP_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d2b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(frame, group_id=0, weights_id=0):\n",
    "\n",
    "    motion = motion_groups[group_id * 11 + weights_id]\n",
    "    display(motion.indices)\n",
    "    q = motion.quats[frame]\n",
    "    p = motion.pos[frame]\n",
    "    \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "\n",
    "    contacts_matrices = np.eye(4, dtype=np.float32)[np.newaxis,...].repeat(2, axis=0)\n",
    "    contacts_matrices = lab.utils.quat_to_mat( motion.constraints_q,  motion.constraints_p )\n",
    "\n",
    "    viewer.draw(target, contacts_matrices)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.draw_axis(contacts_matrices, 20)\n",
    "    viewer.draw_axis(character.world_skeleton_xforms(a), 5)\n",
    "    viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "\n",
    "    for i in motion.indices:\n",
    "        q = clips_q[i, frame, :, :]\n",
    "        p = clips_p[i, frame, :, :]\n",
    "        a = lab.utils.quat_to_mat(q, p)\n",
    "        viewer.draw_lines(character.world_skeleton_lines(a))\n",
    "    \n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1),\n",
    "    group_id=widgets.IntSlider(min=0, max=GROUP_COUNT//11-1, step=1, value=0),\n",
    "    weights_id=widgets.IntSlider(min=0, max=10, step=1, value=0)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fd6df-b875-4621-a500-9b8fd69e302d",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a2c0b-cf17-4012-a714-266695913267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "display(progress_output)\n",
    "\n",
    "# with progress_output:\n",
    "#     physics_costs, delta_theta, delta_x, delta_z = pre_compute_transitions_costs(motion_groups, 'realtime_planning_animations_group_costs.dat')\n",
    "\n",
    "with open('realtime_planning_animations_group_costs.dat', 'rb') as f:\n",
    "    physics_costs, delta_theta, delta_x, delta_z = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4ac13-f549-44cc-98f4-dc65e079d9cb",
   "metadata": {},
   "source": [
    "### Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e275b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_indices = np.arange(len(motion_groups) - 9 * 11, len(motion_groups))\n",
    "stops_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute local position to end on 0,0,0\n",
    "stops_positions = []\n",
    "for id in stops_indices:\n",
    "    player = Player(motion_groups)\n",
    "    player.set_next_clip(id)\n",
    "    player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0] = lab.utils.qp_mul(\n",
    "        lab.utils.qp_inv((player.current_clip.quaternions[player.current_clip.motion.timings[3]-1, 0][np.newaxis,...], player.current_clip.positions[player.current_clip.motion.timings[3]-1, 0][np.newaxis,...])),\n",
    "        (player.current_clip.quaternions[:, 0], player.current_clip.positions[:, 0])\n",
    "    )\n",
    "    pos =  - player.current_clip.positions[player.current_clip.motion.timings[1], 0]\n",
    "    pos = lab.utils.quat_mul_vec(lab.utils.quat_inv(player.current_clip.quaternions[player.current_clip.motion.timings[1], 0]), pos)\n",
    "    stops_positions.append(pos)\n",
    "stops_positions = np.array(stops_positions, dtype=np.float32)\n",
    "stops_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_valid_states = np.zeros([100000000, 4], dtype=np.float32)\n",
    "all_valid_states_count = 0\n",
    "\n",
    "def _rollback_all(state_clip, state_x, state_z, action_id, recursion_counter):\n",
    "    global all_valid_states_count\n",
    "    previous_clip = physics_costs[:, state_clip].argsort()[action_id]\n",
    "    clip_prime, x_prime, z_prime = transition_inv(previous_clip, state_clip, state_x, state_z )\n",
    "    if clip_prime not in stops_indices:\n",
    "        all_valid_states[all_valid_states_count, :] = ((clip_prime, x_prime, z_prime, recursion_counter))\n",
    "        all_valid_states_count += 1\n",
    "        recursion_counter += 1\n",
    "        if recursion_counter < 4:\n",
    "            for i in range(5):\n",
    "                _rollback_all(clip_prime, x_prime, z_prime, i, recursion_counter)\n",
    "\n",
    "for state_clip in stops_indices:\n",
    "    stop_id = np.argwhere(stops_indices == state_clip)[0][0]\n",
    "\n",
    "    for _ in range(1):\n",
    "        x = uniform(-20, 20)\n",
    "        z = uniform(-20, 20)\n",
    "    \n",
    "        for i in range(20):\n",
    "            all_valid_states[all_valid_states_count, :] = ((state_clip, stops_positions[stop_id,0] + x, stops_positions[stop_id,2] + z, 0))\n",
    "            all_valid_states_count += 1\n",
    "            _rollback_all(state_clip,stops_positions[stop_id,0] + x, stops_positions[stop_id,2] + z, i, 1)\n",
    "\n",
    "all_valid_states = all_valid_states[:all_valid_states_count, :]\n",
    "all_valid_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f0e51-bedc-434b-95ed-9a156e6b7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_compute_table_x = np.linspace(-1000, 1000, 1001)\n",
    "pre_compute_table_z = np.linspace(-1000, 1000, 1001)\n",
    "\n",
    "clip_arange = np.arange(GROUP_COUNT)\n",
    "clip_vf_arange = np.arange(int(GROUP_COUNT/11))[np.newaxis, :].repeat(11)\n",
    "\n",
    "clip_arange_no_stop = np.arange(GROUP_COUNT)\n",
    "mask = np.ones(clip_arange_no_stop.shape, bool)\n",
    "mask[stops_indices] = False\n",
    "clip_arange_no_stop = clip_arange_no_stop[mask]\n",
    "\n",
    "clip_vf_arange_no_stop = np.arange(int(GROUP_COUNT/11))[np.newaxis, :].repeat(11)\n",
    "mask = np.ones(clip_vf_arange_no_stop.shape, bool)\n",
    "mask[stops_indices] = False\n",
    "clip_vf_arange_no_stop = clip_vf_arange_no_stop[mask]\n",
    "\n",
    "\n",
    "def use_optimal_policy(value_functions, alpha, state_clip, x, z, no_stop=False):\n",
    "    indices = clip_arange\n",
    "    indices_vf = clip_vf_arange\n",
    "    if no_stop:\n",
    "        indices = clip_arange_no_stop\n",
    "        indices_vf = clip_vf_arange_no_stop\n",
    "        \n",
    "    _, x_prime, z_prime = transition(state_clip, x, z, indices)\n",
    "\n",
    "    reward = transition_reward(state_clip, indices) * .4\n",
    "    reward += alpha * get_value_function(value_functions, indices_vf, x_prime, z_prime)\n",
    "\n",
    "    picked = np.argmax(reward)\n",
    "\n",
    "    # now let's forbid taking a transition toward a stop if it fails\n",
    "    if no_stop==False and state_reward(clip_arange[picked], x_prime[picked], z_prime[picked]) < -99:\n",
    "        return use_optimal_policy(value_functions, alpha, state_clip, x, z, True)\n",
    "\n",
    "    return indices[picked], x_prime[picked], z_prime[picked], reward[picked] + state_reward(state_clip, x, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ee9fa-6c64-47a9-b335-723e279d0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_VALUE_COUNT = int(GROUP_COUNT/11)\n",
    "value_functions_precompute = np.zeros([GROUP_VALUE_COUNT, pre_compute_table_x.shape[0], pre_compute_table_z.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43712ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "display(progress_output)\n",
    "\n",
    "ALPHA = .99\n",
    "EPOCH = 15\n",
    "RESTART_EPOCH = 100\n",
    "LEARN_RATE = 0.1\n",
    "REPEAT_FITTING = 1\n",
    "\n",
    "PRE_COMPUTE_TABLE_INDICES = np.stack(np.meshgrid(pre_compute_table_x, pre_compute_table_z), axis=2).reshape(-1, 2)\n",
    "\n",
    "def _generate_data(count, X, y, clip_index):\n",
    "    # force all the known path\n",
    "    for s in all_valid_states[::3]:\n",
    "        clip, x, z, rec = int(s[0]), s[1], s[2], s[3]\n",
    "        clip_group = int(clip/11)\n",
    "        clip_index[clip_group, count[clip_group]] = clip\n",
    "        X[clip_group, count[clip_group], 0] = x\n",
    "        X[clip_group, count[clip_group], 1] = z\n",
    "        y[clip_group, count[clip_group]] = 1.0 * (ALPHA ** rec)\n",
    "        count[clip_group] += 1\n",
    "        \n",
    "\n",
    "def train_optimal_policy():\n",
    "    progress_output.clear_output()\n",
    "\n",
    "    scores = np.zeros([EPOCH, 4])\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            display(f\"epoch : [{epoch}]\")\n",
    "\n",
    "            if epoch % RESTART_EPOCH == 0:\n",
    "                display(f\"bootstrap\")\n",
    "                count = np.zeros([GROUP_VALUE_COUNT], dtype=np.uint32)\n",
    "                clip_index = np.zeros([GROUP_VALUE_COUNT, 100000], dtype=np.uint32)\n",
    "                X = np.zeros([GROUP_VALUE_COUNT, 100000, 2])\n",
    "                y = np.zeros([GROUP_VALUE_COUNT, 100000])\n",
    "                _generate_data(count, X, y, clip_index)\n",
    "\n",
    "            # else:\n",
    "            #     # keep only alf of the previous data\n",
    "            #     for i in range(GROUP_VALUE_COUNT):\n",
    "            #         count[i] /= 2\n",
    "                \n",
    "            #build a data set\n",
    "            display(f\"gather path data\")\n",
    "            reach_reward = 0\n",
    "\n",
    "            for _ in range(1):\n",
    "                for clip in range(GROUP_COUNT):\n",
    "                    # dist = 100 + 500 * (float(epoch) / float(EPOCH))\n",
    "                    dist = 500\n",
    "                    x = uniform(-dist, dist)\n",
    "                    z = uniform(-dist, dist)\n",
    "            \n",
    "                    for steps in range(10):\n",
    "                        if state_reward(clip, x, z) >= 1:\n",
    "                            reach_reward += 1\n",
    "                            break\n",
    "                        \n",
    "                        c, x_prime, z_prime, reward = use_optimal_policy(value_functions_precompute, ALPHA, clip, x, z)\n",
    "                        \n",
    "                        clip_group = int(clip/11)\n",
    "\n",
    "                        clip_index[clip_group, count[clip_group]] = clip\n",
    "                        X[clip_group, count[clip_group], 0] = x\n",
    "                        X[clip_group, count[clip_group], 1] = z\n",
    "                        y[clip_group, count[clip_group]] = reward\n",
    "                        count[clip_group] += 1\n",
    "        \n",
    "                        clip = c\n",
    "                        x = x_prime\n",
    "                        z = z_prime\n",
    "    \n",
    "            # found \n",
    "            display(f\"found {reach_reward} succesful paths\")\n",
    "                \n",
    "            for _ in range(REPEAT_FITTING):    \n",
    "                #train the value functions\n",
    "                display(f\"train the value functions\")\n",
    "                args = [(X[i, :count[i]], y[i, :count[i]], PRE_COMPUTE_TABLE_INDICES, pre_compute_table_x.shape[0]) for i in range(GROUP_VALUE_COUNT)]\n",
    "                results = pool.starmap(mpf.reach_train_value_function, args)\n",
    "                value_functions_precompute[:, :, :] = np.stack(results)\n",
    "                \n",
    "                #compute bellman residual\n",
    "                residuals = np.zeros([GROUP_VALUE_COUNT * 10000])\n",
    "                c = 0\n",
    "        \n",
    "                display(f\"re evaluate Value functions\")\n",
    "                for i in range(GROUP_VALUE_COUNT):\n",
    "                    for j in range(count[i]):\n",
    "                        _, _, _, reward = use_optimal_policy(value_functions_precompute, ALPHA, clip_index[i,j], X[i,j, 0], X[i,j, 1])\n",
    "        \n",
    "                        residuals[c] = np.abs(y[i, j] - reward)\n",
    "                        \n",
    "                        y[i, j] += LEARN_RATE * (reward - y[i, j])\n",
    "                        c+=1\n",
    "        \n",
    "                progress_output.clear_output()\n",
    "                display(f\"residuals; mean {residuals[:c].mean()} max {residuals[:c].max()} total states count {np.sum(count)}\")\n",
    "                scores[epoch, 0] = residuals[:c].min()\n",
    "                scores[epoch, 1] = residuals[:c].max()\n",
    "                scores[epoch, 2] = residuals[:c].mean()\n",
    "                scores[epoch, 3] = reach_reward\n",
    "    \n",
    "    with open('realtime_planning_reach_position_group_value_functions.dat', 'wb') as f:\n",
    "        pickle.dump((value_functions_precompute, scores), f)\n",
    "\n",
    "    return value_functions_precompute, scores\n",
    "\n",
    "# with progress_output:\n",
    "#     value_functions_precompute, scores = train_optimal_policy()\n",
    "\n",
    "with open('realtime_planning_reach_position_group_value_functions.dat', 'rb') as f:\n",
    "    value_functions_precompute, scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(EPOCH)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# First subplot\n",
    "axs[0].plot(x, scores[:, 2], label='Mean', color='blue')\n",
    "axs[0].fill_between(x, scores[:, 0], scores[:, 1], color='lightblue', alpha=0.4, label='Min-Max Range')\n",
    "axs[0].set_title('Scores over Epoch (Mean and Range)')\n",
    "axs[0].set_ylabel('Value')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Second subplot\n",
    "axs[1].plot(x, scores[:, 3], label='Found', color='blue')\n",
    "axs[1].set_title('Scores over Epoch (Found)')\n",
    "axs[1].set_xlabel('Index')\n",
    "axs[1].set_ylabel('Value')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "player = Player(motion_groups)\n",
    "player.set_next_clip(62 * 11)\n",
    "player.target = np.array([-200, 0, 500], dtype=np.float32)\n",
    "player.wait_counter = 0\n",
    "\n",
    "def render(frame):\n",
    "\n",
    "    if player.next_clip is None and player.current_clip.motion.timings[1] <= player.current_clip.frame:\n",
    "        if player.current_clip.motion._id not in stops_indices:\n",
    "\n",
    "            pos = player.target - player.positions[0, :]\n",
    "            pos = lab.utils.quat_mul_vec(lab.utils.quat_inv(player.quaternions[0, :]), pos)\n",
    "\n",
    "            # if we reach the reward we can transition to a stop\n",
    "            if state_reward(player.current_clip.motion._id, pos[0], pos[2]) > 1:\n",
    "                index = physics_costs[player.current_clip.motion._id, stops_indices].argmin()\n",
    "                player.set_next_clip(stops_indices[index])\n",
    "\n",
    "            else:\n",
    "                next_clip, x_prime, z_prime, reward = use_optimal_policy(value_functions_precompute, ALPHA, player.current_clip.motion._id, pos[0], pos[2])\n",
    "                display((pos, next_clip, x_prime, z_prime, reward))\n",
    "            \n",
    "                player.set_next_clip(next_clip)\n",
    "        else:\n",
    "            player.wait_counter += 1\n",
    "            if player.wait_counter > 15:\n",
    "                new_target = np.array([uniform(-300, 300), 0, uniform(-300, 300)], dtype=np.float32)\n",
    "                while (np.sum((player.target - new_target)**2) < 250):\n",
    "                    new_target = np.array([uniform(-300, 300), 0, uniform(-300, 300)], dtype=np.float32)\n",
    "                player.target = new_target\n",
    "                player.set_next_clip(62 * 11)\n",
    "                player.wait_counter = 0\n",
    "\n",
    "    player.tick()\n",
    "    \n",
    "    q = player.quaternions\n",
    "    p = player.positions\n",
    " \n",
    "    a = lab.utils.quat_to_mat(q, p)\n",
    "    viewer.set_shadow_poi(p[0])\n",
    "    \n",
    "    viewer.begin_shadow()\n",
    "    viewer.draw(character, a)\n",
    "    viewer.end_shadow()\n",
    "    \n",
    "    viewer.begin_display()\n",
    "    viewer.draw_ground()\n",
    "    viewer.draw(character, a)\n",
    "    d = lab.utils.quat_to_mat(np.array([1,0,0,0], dtype=np.float32), player.target)\n",
    "    viewer.draw(target, d)\n",
    "    \n",
    "    viewer.end_display()\n",
    "\n",
    "    viewer.disable(depth_test=True)\n",
    "\n",
    "    viewer.execute_commands()\n",
    "    \n",
    "interact(\n",
    "    render, \n",
    "    frame=lab.Timeline(max=MAX_STEP_LEN-1)\n",
    ")\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8dc43-537c-46ca-b805-0bcffb384e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b7343-23ff-4a01-a2b9-5df49cbfa017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
